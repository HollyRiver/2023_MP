{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d50df5-bcd4-49d1-a13c-4fc8df4ddd8c",
   "metadata": {},
   "source": [
    "## code summation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81fcd3-580b-4406-b44b-9fa75d321662",
   "metadata": {},
   "source": [
    "### **1. Analysis and Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd608422-33f4-4a2a-89e0-df8a4d36778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2bfdf-8df6-4154-800c-4bea66616c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('file derectort')  ## csv 데이터를 DataFrame으로 읽어온다. 직접 입력 또는 간접(.) 입력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172ea5a-0fde-42f3-84dc-622944ef2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file name', index = bool)  ## DataFrame을 현재 디렉토리에 csv 파일로 저장한다. index = False로 지정 시 인덱스를 누락시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4743be8-382c-43a7-af09-36f53b4592a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df)  ## DataFrame의 범주형 자료를 포함한 열을 더미변수로 만들어준다. 회귀에 유리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb20f23-083c-45a4-84c9-c1a9fb73955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators = int, max_depth = int, random_state = int)  ## 뭔진 모르겠지만 아무튼 추정하는 모델이다. predictr에 저장하여 predictr.fit(X, y)해주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d1996-a924-4860-aa66-ab4fb5d8fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis cycle, 분석 과정\n",
    "##----1. data----\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X = train.loc[:, features]\n",
    "y = train.loc[:, response]\n",
    "XX = test.loc[: features]\n",
    "##yy = test.loc[:, response] ## 보통 주어지지 않음\n",
    "\n",
    "##----2. predictor----\n",
    "predictr = ...model...\n",
    "\n",
    "##----3. fitting----\n",
    "predictr.fit(X, y)\n",
    "predictr.score(X, y)  ## or another method\n",
    "\n",
    "##----4. submission----\n",
    "test.assign(response = predictr.predict(XX)).loc[:, response].to_csv('file name', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824385c6-963b-4cdf-8aaf-8ecd990c9d89",
   "metadata": {},
   "source": [
    "### **2. autogluon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f8366b-eb58-409f-9624-e561c323e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !pip install autogluon  ## colab or kaggle notebook. 이미 환경이 구성되어 있다면 필요없음.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e89b5c-de31-46ad-a5d0-5a49026fa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularDataset('file derectory')  ## pd.read_csv()와 비슷한 코드라고 보면 된다. 실제로 해당 개체를 다루는 방식이 거의 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb2df1-1e4f-4c85-9576-beb422c5f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis cycle\n",
    "\n",
    "#----1. data----\n",
    "train = TabularDataset('train.csv directory')\n",
    "test = TabularDataset('test.csv directory')\n",
    "\n",
    "#X = train.drop([반응변수 열], axis = 1)\n",
    "#y = train[반응변수 열]\n",
    "#XX = test.drop([반응변수 열], axis = 1)\n",
    "#상기 과정이 필요없다.\n",
    "\n",
    "#----2. create predictor----\n",
    "predictr = TabularPredictor(반응변수 열)\n",
    "\n",
    "#----3. fitting----\n",
    "predictr.fit(train)  ## 다른 선형회귀에선 설명변수와 반응변수를 나눠줬지만, 여기선 한번에 입력했다. 이미 predictr에 무엇이 반응변수인지 지정해줬기 때문이다.\n",
    "(train[반응변수 열] == predictr.predict(X)).mean()  ## 몇 퍼센트가 맞는 지 산출해준다. score에 해당한다.\n",
    "\n",
    "#----4. submittion----\n",
    "test.assign(반응변수 열 = predictr.predict(XX)).loc[:, 제출에 필요한 열].to_csv(디렉토리, index = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba18c09-96db-4e1c-a9e8-97d6be659628",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.leaderboard()  ## fitting을 마친 predictr가 사용한 모델들의 성능 순위가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6ecdc0-382d-4788-8ab5-aaf9be111f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# 유사한 정보를 가지고 있는 여러 열들을 하나로 합치면 더 좋은 결과가 나온다(다중 공선성 해결 등)\n",
    "train.assign(Fsize = train.Sibsp + train.Parch).drop(['Sibsp', 'Parch'], axis = 1)  ## 동승한 가족의 수를 합하고, 기존 자료는 제거해야 한다. 그렇지 않으면 다중공선성 문제가 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361b10e-98b0-428d-ba38-1b02cdd7f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.fit(train, presets = 'best_quality')  ##  presets에 설정된 옵션 소환. 자원을 전부 지원해줄 테니, 가장 좋은 퀄리티를 내놓아라. > 시간 오래걸림, 성능 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c11e2b-8210-49b9-8ddc-1f8a938ad430",
   "metadata": {},
   "source": [
    "### **3. Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf1349c-46b2-480d-a64e-eae48f8ae1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f30629-c73f-4e53-817c-715dde09b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cycle\n",
    "\n",
    "## step 1\n",
    "X = pd.get_dummies(df_train.drop([반응변수 열], axis = 1))  ## 범주형 자료가 있을 때 반드시 사용\n",
    "y = df_train[반응변수열]\n",
    "XX = pd.get_dimmies(df_train)\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "predictr.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253dab27-ec60-4aa9-b0cf-b2d69500b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.coef_  ## coefficient, 계수를 내준다.\n",
    "predictr.intercept_  ## 절편을 내준다. 둘다 array로 반환하므로 사용 시 변환이 필요\n",
    "predictr.score(X, y)  ## R^2_score 값을 산출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9cc0b-33cc-486d-ac14-ea2019dbaa24",
   "metadata": {},
   "source": [
    "### **4. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8509f291-26bf-4c12-938f-bae2318f6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6275e-ba9b-4b2f-96e8-1d43fa74f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cycle\n",
    "\n",
    "## step 1\n",
    "X = pd.get_dummies(df_train.drop([반응변수 열], axis = 1))\n",
    "y = df_train[반응변수 열]\n",
    "XX = pd.get_dummies(df_test)\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "predictr.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ad1ad-f4fc-4fb5-89a5-931a68a2e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.score(X, y)  ## 예측한 반응변수가 원 반응변수 열 대비 얼마나 맞는 지 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a772412-1ce1-45ee-9ed7-35f6d872a1d4",
   "metadata": {},
   "source": [
    "### **5. 결측치 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1472de-f878-4280-a169-a342e8722235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import sklearn.impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9004e-106f-413b-ad9b-d4987a38ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info  ## 해당 결과 시 결측치가 많아보인다면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f8b08-644e-4b82-a3ba-13819cdc0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)  ## 특정 행에 결측치가 얼마나 있는지 시각화한다.\n",
    "msno.heatmap(df)  ## 결측치가 있는 구조(특정 행 부분에 밀집된 정도)가 비슷한 것 끼리 상관계수 내듯이\n",
    "msno.dendrogram(df)  ## 결측치 존재 구조가 비슷한 행끼리 엮어놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb9b93-241b-406a-8792-034e15f9b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr = sklearn.impute.SimpleImputer(strategy = '통계량 타입', fill_value = '채울 값')\n",
    "## strategy = 'mean', 'most_frequent', 'median',  'constant' > fill_value = 'value'\n",
    "imputr.fit(df)\n",
    "imputr.transform(df)  ## imputr.fit_transform(df) > 피팅과 전환을 한번에!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977da07-762c-462e-9758-0ac97fdbbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(imputr.fit_transform(df).reshape(-1))\n",
    "## impute 후 pd.Series로 전환할 때 꼭 1차원 배열로 바꿀 것! Series는 2차원 이상의 배열을 받을 수 없다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab213d5e-3c9e-4fc7-afdd-7bd628191f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr_int = sklearn.impute.SimpleImputer(strategy = 'mean')\n",
    "imputr_obj = sklearn.impute.SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "imputr_int.fit_transform(df.select_dtypes(include = 'number'))\n",
    "imputr_int.fit_transform(df.select_dtypes(exclude = 'number'))\n",
    "\n",
    "## df.select_dtypes()를 통해 형식에 따라 데이터프레임을 손쉽게 나누고, 각자 impute할 대상을 지정해줄 수 있다.\n",
    "## 일반적으로 범주형은 최빈값, 연속형은 평균으로 impute한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d1425-4202-4b38-9096-caea451f10e5",
   "metadata": {},
   "source": [
    "### **6. 로지스틱에서의 결측치 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5627bdf8-58b6-47c9-805b-65b6a8dbdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46c0f9-7b29-4af9-8aec-0cebbc6f8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df):\n",
    "    \"\"\"\n",
    "    It impute missing, output imputed DataFrame.\n",
    "    \n",
    "    df : DataFrame include NaN value\n",
    "    \"\"\"\n",
    "    df_ = df.copy()  ## 데이터를 복사, 기존 데이터를 바꾸게 될 수도 있으므로 매우 유용하다.\n",
    "    \n",
    "    df_num = df_.select_dtypes(include = 'number')  ## 해당하는 데이터 타입만 선택\n",
    "    df_obj = df_.select_dtypes(exclude = 'number')\n",
    "    \n",
    "    df_[df_num.columns] = sklearn.impute.SimpleImputer(strategy = 'mean').fit_transform(df_num)\n",
    "    df_[df_obj.columns] = sklearn.impute.SimpleImputer(strategy = 'most_frequent').fit_transform(df_obj)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "## imputing하는 함수를 만든다. train, test셋을 다루려면 최소한 두 번은 imputing을 해야 하니... 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fce7a0-c17a-457c-8723-98feab6da594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(impute_missing(df_train))  ## 범주형 열에 사용 시 주의해야 한다. 고유값을 가지는 열(이름, 티켓번호 등...)의 경우 더미를 행의 수만큼 만들수도 있음...\n",
    "## 꼭 필요없는 열은 드롭하고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b759c-7c3e-4d80-9275-24e203804008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "X = pd.get_dummies(impute_missing(df_train.drop([고유값을 가지는 열들, 반응변수 열], axis = 1)))\n",
    "y = df_train['반응변수 열']\n",
    "XX = pd.get_dummies(impute_missing(df_test.drop([고유값을 가지는 열들], axis = 1)))\n",
    "\n",
    "## step 2\n",
    "## 기본 로지스틱 회귀분석 방법과 동일..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d19e6c-9557-4e26-ac11-d9d845b509d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
