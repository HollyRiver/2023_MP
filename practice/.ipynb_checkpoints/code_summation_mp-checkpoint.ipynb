{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d50df5-bcd4-49d1-a13c-4fc8df4ddd8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Midterm Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81fcd3-580b-4406-b44b-9fa75d321662",
   "metadata": {},
   "source": [
    "### **1. Analysis and Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd608422-33f4-4a2a-89e0-df8a4d36778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## 왠만해선 그냥 sklearn과 연관되게 직접 import하자..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d2bfdf-8df6-4154-800c-4bea66616c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file derectort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile derectort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m## csv 데이터를 DataFrame으로 읽어온다. 직접 입력 또는 간접(.) 입력.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file derectort'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('file derectort')  ## csv 데이터를 DataFrame으로 읽어온다. 직접 입력 또는 간접(.) 입력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172ea5a-0fde-42f3-84dc-622944ef2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file name', index = bool)  ## DataFrame을 현재 디렉토리에 csv 파일로 저장한다. index = False로 지정 시 인덱스를 누락시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4743be8-382c-43a7-af09-36f53b4592a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df)  ## DataFrame의 범주형 자료를 포함한 열을 더미변수로 만들어준다. 회귀에 유리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb20f23-083c-45a4-84c9-c1a9fb73955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators = int, max_depth = int, random_state = int)  ## 뭔진 모르겠지만 아무튼 추정하는 모델이다. predictr에 저장하여 predictr.fit(X, y)해주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d1996-a924-4860-aa66-ab4fb5d8fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis cycle, 분석 과정\n",
    "##----1. data----\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X = train.loc[:, features]\n",
    "y = train.loc[:, target]\n",
    "XX = test.loc[: features]\n",
    "##yy = test.loc[:, target] ## 보통 주어지지 않음\n",
    "\n",
    "##----2. predictor----\n",
    "predictr = ...model...\n",
    "\n",
    "##----3. fitting----\n",
    "predictr.fit(X, y)\n",
    "predictr.score(X, y)  ## or another method\n",
    "\n",
    "##----4. submission----\n",
    "test.assign(response = predictr.predict(XX)).loc[:, response].to_csv('file name', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824385c6-963b-4cdf-8aaf-8ecd990c9d89",
   "metadata": {},
   "source": [
    "### **2. autogluon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8366b-eb58-409f-9624-e561c323e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autogluon  ## colab or kaggle notebook. 이미 환경이 구성되어 있다면 필요없음.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e89b5c-de31-46ad-a5d0-5a49026fa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularDataset('file derectory')  ## pd.read_csv()와 비슷한 코드라고 보면 된다. 실제로 해당 개체를 다루는 방식이 거의 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb2df1-1e4f-4c85-9576-beb422c5f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis cycle\n",
    "\n",
    "#----1. data----\n",
    "train = TabularDataset('train.csv directory')\n",
    "test = TabularDataset('test.csv directory')\n",
    "\n",
    "#X = train.drop([반응변수 열], axis = 1)\n",
    "#y = train[반응변수 열]\n",
    "#XX = test.drop([반응변수 열], axis = 1)\n",
    "#상기 과정이 필요없다.\n",
    "\n",
    "#----2. create predictor----\n",
    "predictr = TabularPredictor(반응변수 열)\n",
    "\n",
    "#----3. fitting----\n",
    "predictr.fit(train)  ## 다른 선형회귀에선 설명변수와 반응변수를 나눠줬지만, 여기선 한번에 입력했다. 이미 predictr에 무엇이 반응변수인지 지정해줬기 때문이다.\n",
    "(train[반응변수 열] == predictr.predict(X)).mean()  ## 몇 퍼센트가 맞는 지 산출해준다. score에 해당한다.\n",
    "\n",
    "#----4. submittion----\n",
    "test.assign(반응변수 열 = predictr.predict(XX)).loc[:, 제출에 필요한 열].to_csv(디렉토리, index = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba18c09-96db-4e1c-a9e8-97d6be659628",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.leaderboard()  ## fitting을 마친 predictr가 사용한 모델들의 성능 순위가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ecdc0-382d-4788-8ab5-aaf9be111f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# 유사한 정보를 가지고 있는 여러 열들을 하나로 합치면 더 좋은 결과가 나온다(다중 공선성 해결 등)\n",
    "train.assign(Fsize = train.Sibsp + train.Parch).drop(['Sibsp', 'Parch'], axis = 1)  ## 동승한 가족의 수를 합하고, 기존 자료는 제거해야 한다. 그렇지 않으면 다중공선성 문제가 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361b10e-98b0-428d-ba38-1b02cdd7f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.fit(train, presets = 'best_quality')  ##  presets에 설정된 옵션 소환. 자원을 전부 지원해줄 테니, 가장 좋은 퀄리티를 내놓아라. > 시간 오래걸림, 성능 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c11e2b-8210-49b9-8ddc-1f8a938ad430",
   "metadata": {},
   "source": [
    "### **3. Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1349c-46b2-480d-a64e-eae48f8ae1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f30629-c73f-4e53-817c-715dde09b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cycle\n",
    "\n",
    "## step 1\n",
    "X = pd.get_dummies(df_train.drop([반응변수 열], axis = 1))  ## 범주형 자료가 있을 때 반드시 사용\n",
    "y = df_train[반응변수열]\n",
    "XX = pd.get_dimmies(df_train)\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "predictr.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253dab27-ec60-4aa9-b0cf-b2d69500b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.coef_  ## coefficient, 계수를 내준다.\n",
    "predictr.intercept_  ## 절편을 내준다. 둘다 array로 반환하므로 사용 시 변환이 필요\n",
    "predictr.score(X, y)  ## R^2_score 값을 산출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9cc0b-33cc-486d-ac14-ea2019dbaa24",
   "metadata": {},
   "source": [
    "### **4. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509f291-26bf-4c12-938f-bae2318f6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6275e-ba9b-4b2f-96e8-1d43fa74f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cycle\n",
    "\n",
    "## step 1\n",
    "X = pd.get_dummies(df_train.drop([반응변수 열], axis = 1))\n",
    "y = df_train[반응변수 열]\n",
    "XX = pd.get_dummies(df_test)\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "predictr.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ad1ad-f4fc-4fb5-89a5-931a68a2e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.score(X, y)  ## 예측한 반응변수가 원 반응변수 열 대비 얼마나 맞는 지 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a772412-1ce1-45ee-9ed7-35f6d872a1d4",
   "metadata": {},
   "source": [
    "### **5. 결측치 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1472de-f878-4280-a169-a342e8722235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import sklearn.impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9004e-106f-413b-ad9b-d4987a38ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info  ## 해당 결과 시 결측치가 많아보인다면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f8b08-644e-4b82-a3ba-13819cdc0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)  ## 특정 행에 결측치가 얼마나 있는지 시각화한다.\n",
    "msno.heatmap(df)  ## 결측치가 있는 구조(특정 행 부분에 밀집된 정도)가 비슷한 것 끼리 상관계수 내듯이\n",
    "msno.dendrogram(df)  ## 결측치 존재 구조가 비슷한 행끼리 엮어놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb9b93-241b-406a-8792-034e15f9b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr = sklearn.impute.SimpleImputer(strategy = '통계량 타입', fill_value = '채울 값')\n",
    "## strategy = 'mean', 'most_frequent', 'median',  'constant' > fill_value = 'value'\n",
    "imputr.fit(df)\n",
    "imputr.transform(df)  ## imputr.fit_transform(df) > 피팅과 전환을 한번에!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977da07-762c-462e-9758-0ac97fdbbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(imputr.fit_transform(df).reshape(-1))\n",
    "## impute 후 pd.Series로 전환할 때 꼭 1차원 배열로 바꿀 것! Series는 2차원 이상의 배열을 받을 수 없다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab213d5e-3c9e-4fc7-afdd-7bd628191f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr_int = sklearn.impute.SimpleImputer(strategy = 'mean')\n",
    "imputr_obj = sklearn.impute.SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "imputr_int.fit_transform(df.select_dtypes(include = 'number'))\n",
    "imputr_int.fit_transform(df.select_dtypes(exclude = 'number'))\n",
    "\n",
    "## df.select_dtypes()를 통해 형식에 따라 데이터프레임을 손쉽게 나누고, 각자 impute할 대상을 지정해줄 수 있다.\n",
    "## 일반적으로 범주형은 최빈값, 연속형은 평균으로 impute한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d1425-4202-4b38-9096-caea451f10e5",
   "metadata": {},
   "source": [
    "### **6. 로지스틱에서의 결측치 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627bdf8-58b6-47c9-805b-65b6a8dbdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46c0f9-7b29-4af9-8aec-0cebbc6f8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df):\n",
    "    \"\"\"\n",
    "    It impute missing, output imputed DataFrame.\n",
    "    \n",
    "    df : DataFrame include NaN value\n",
    "    \"\"\"\n",
    "    df_ = df.copy()  ## 데이터를 복사, 기존 데이터를 바꾸게 될 수도 있으므로 매우 유용하다.\n",
    "    \n",
    "    df_num = df_.select_dtypes(include = 'number')  ## 해당하는 데이터 타입만 선택\n",
    "    df_obj = df_.select_dtypes(exclude = 'number')\n",
    "    \n",
    "    df_[df_num.columns] = sklearn.impute.SimpleImputer(strategy = 'mean').fit_transform(df_num)\n",
    "    df_[df_obj.columns] = sklearn.impute.SimpleImputer(strategy = 'most_frequent').fit_transform(df_obj)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "## imputing하는 함수를 만든다. train, test셋을 다루려면 최소한 두 번은 imputing을 해야 하니... 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fce7a0-c17a-457c-8723-98feab6da594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(impute_missing(df_train))  ## 범주형 열에 사용 시 주의해야 한다. 고유값을 가지는 열(이름, 티켓번호 등...)의 경우 더미를 행의 수만큼 만들수도 있음...\n",
    "## 꼭 필요없는 열은 드롭하고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b759c-7c3e-4d80-9275-24e203804008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "X = pd.get_dummies(impute_missing(df_train.drop([고유값을 가지는 열들, 반응변수 열], axis = 1)))\n",
    "y = df_train['반응변수 열']\n",
    "XX = pd.get_dummies(impute_missing(df_test.drop([고유값을 가지는 열들], axis = 1)))\n",
    "\n",
    "## step 2\n",
    "## 기본 로지스틱 회귀분석 방법과 동일..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6bd10-fca7-42f5-a349-cbb3b583ee62",
   "metadata": {},
   "source": [
    "### **7. predictor의 이해**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac9f2b-ddcc-4fbb-95fd-48c8a589ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53ac10-3300-4a92-819b-ff715f9057ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 로지스틱 회귀분석의 원리\n",
    "## 해당 개체에 처리가 취해질 확률이 0.5보다 크면 1, 0.5보다 작으면 0\n",
    "\n",
    "## 1\n",
    "X = df.drop(['employment'], axis = 1)\n",
    "y = df.employment\n",
    "\n",
    "## 2\n",
    "predictr = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "## 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## 4\n",
    "predictr.predict(X)  ## yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d7228-a87e-4244-b4b6-56990d84e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상기 과정에서 각 개체의 확률을 알고 싶으면...\n",
    "predictr.predict_proba(X)  ## n by 2의 행렬을 산출한다. 첫 행은 0일 확률, 둘째 행은 1일 확률이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c586a-3f27-4699-b7ff-aeb0d743f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = {'DataFrame(2d)': df_train_X, \n",
    "      'Seires(1d)': df_train_X.X,\n",
    "      'ndarray(2d)': np.array(df_train_X),\n",
    "      'ndarray(1d)': np.array(df_train_X).reshape(-1),\n",
    "      'list(2d)': np.array(df_train_X).tolist(),\n",
    "      'list(1d)': np.array(df_train_X).reshape(-1).tolist()}\n",
    "\n",
    "ys = {'DataFrame(2d)': df_train_y, \n",
    "      'Seires(1d)': df_train_y.y,\n",
    "      'ndarray(2d)': np.array(df_train_y),\n",
    "      'ndarray(1d)': np.array(df_train_y).reshape(-1),\n",
    "      'list(2d)': np.array(df_train_y).tolist(),\n",
    "      'list(1d)': np.array(df_train_y).reshape(-1).tolist()}\n",
    "\n",
    "def test(X,y):\n",
    "    try: \n",
    "        predictr = sklearn.linear_model.LinearRegression()\n",
    "        predictr.fit(X,y)\n",
    "        return 'no error'\n",
    "    except:\n",
    "        return 'error'  ## 예외사항(error) 발생 시의 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5989a3-3369-4ae7-8c8d-6fa61a10d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, y에 들어갈 수 있는 형식\n",
    "\n",
    "{('X='+i,'y='+j): test(Xs[i],ys[j]) for i,j in itertools.product(Xs.keys(),ys.keys())}\n",
    "\n",
    "## itertools.product() : 원소들의 데카르트 곱을 리스트로 반환.\n",
    "## itertools.product('ABCD', repeat = 2)의 경우 크기가 2인 앞의 string 조합을 모두 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddd699-b680-43e7-921c-1dd8045d2f0e",
   "metadata": {},
   "source": [
    "```\n",
    "{('X=DataFrame(2d)', 'y=DataFrame(2d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=Seires(1d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=ndarray(2d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=ndarray(1d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=list(2d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=list(1d)'): 'no error',\r\n",
    " ('X=Seires(1d)', 'y=DataFrame(2d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=Seires(1d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=ndarray(2d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=ndarray(1d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=list(2d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=list(1d)'): 'error',\r\n",
    " ('X=ndarray(2d)', 'y=DataFrame(2d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=Seires(1d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=ndarray(2d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=ndarray(1d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=list(2d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=list(1d)'): 'no error',\r\n",
    " ('X=ndarray(1d)', 'y=DataFrame(2d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=Seires(1d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=ndarray(2d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=ndarray(1d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=list(2d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=list(1d)'): 'error',\r\n",
    " ('X=list(2d)', 'y=DataFrame(2d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=Seires(1d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=ndarray(2d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=ndarray(1d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=list(2d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=list(1d)'): 'no error',\r\n",
    " ('X=list(1d)', 'y=DataFrame(2d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=Seires(1d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=ndarray(2d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=ndarray(1d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=list(2d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=list(1d)'): 'error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea526b9-4346-42f4-b007-e8fd2941a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X에는 2차원 데이터만, y에는 1차원 2차원 모두 올 수 있다. y는 1차원 데이터를 은근히 바라고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca2548-1cfa-4a80-8388-695420b91df5",
   "metadata": {},
   "source": [
    "### **8. 스케일링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71123b85-e487-4a42-9d38-86c164658fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccade47-ebb8-4298-9456-184776d25df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr = sklearn.preprocessing.MinMaxScaler()\n",
    "imputr.fit_transform(X)\n",
    "imputr.transform(XX)\n",
    "## sklearn.preprocessing.minmax_scale(X)  ## 잘 쓰진 않는다. XX에 똑같은 변환을 못해줌\n",
    "\n",
    "imputr = sklearn.preprocessing.StandardScaler()\n",
    "imputr.fit_transform(X)\n",
    "imputr.transform(XX)\n",
    "\n",
    "## X에서 fitting했으면 XX에는 fitting하지 않고 그대로 변환해주는 게 합리적이다.\n",
    "## X와 XX를 합쳐서 fitting하면 실격이다. 정보누수임(실제로는 그럴 일이 없으니까)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22bfa4-c25d-42c3-8c6c-07d33c1b66a1",
   "metadata": {},
   "source": [
    "1. **MinMaxSclaer**:\n",
    "    * 장점 : 원하는 범위 내로 데이터를 조정할 때 유용, 특히 신경망에서는 활성화 함수의 범위와 일치하도록 입력값을 조정하는 데 유용.\n",
    "    * 단점 : 이상치에 매우 민감하다.\n",
    "\n",
    "1. **StandardScaler**:\n",
    "   * 장점 : **이상치에 덜 민감**함, 많은 통계적 기법들 - **선형 알고리즘에서 잘 작동**함\n",
    "   * 단점 : 표준화된 데이터의 값이 특정 범위 내에 있음을 보장하지 않음.\n",
    "  \n",
    "> 단순히 MinMaxScaler는 데이터가 0\\~1 또는 -1~1사이의 범위에 있다고 가정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af1602-bcbe-452c-ab58-2e9616a5f7ac",
   "metadata": {},
   "source": [
    "### **9. 오버피팅, 다중공선성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d95b3-95b3-4042-aac4-1f30600595d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677de24-f505-4c7a-a4cf-c51b46c6725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'str{}ing'.format(중괄호 안에 입력할 값)  ## 스트링 안에 중괄호가 있다면 언제든지 가능\n",
    "f'str{입력값:.4f}ing'  ## f스트링, 괄호 안에 특정 입력값을 넣어줄 수 있다.\n",
    "r'string'  ## markdown 문법으로 수식 작성 가능, ex) $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17125fd-a3b1-4290-93d7-c51bc0c1133f",
   "metadata": {},
   "source": [
    "> 반응변수와 관련성이 낮은 설명변수는(없는 설명변수) 오버피팅을 유발한다. 즉, 오차항을 적합하게 만든다.\n",
    ">\n",
    "> 설명변수끼리의 상관성이 높은 경우, 해당 설명변수들이 반응변수와의 상관성이 높더라도 오버피팅을 유발하고 이것을 다중공선성이라고 한다.\n",
    ">\n",
    "> 계수들의 합은 실제 계수와 동일하게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f29758-e766-4ef3-ab17-9315426656a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.model_selection.train_test_split(df, test_size = 0.3, random_state = value)\n",
    "## df_train, df_test를 순서대로 산출한다. 랜덤으로 샘플을 추출하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efb5d8-a0fb-4b80-a5ae-5796145b88c8",
   "metadata": {},
   "source": [
    "### **10. Lasso, Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1198c-639b-4fab-ad58-aa67945b0a42",
   "metadata": {},
   "source": [
    "`Lasso` : L1 penalty, `LogisticRegressionCV`의 옵션 `penalty = 'l1' solver = 'liblinear'`로 사용가능\n",
    "\n",
    ": 다수의 coef 값들을 0으로 만드는 수학적 장치\n",
    "\n",
    "> 패널티 : 상관성이 짙은 설명변수들의 계수값의 절대값을 구한 뒤에 합치고(L1-norm을 구하고), 그 값이 0에서 떨어져 있을수록 패널티 부여.\n",
    ">\n",
    "> **불필요한 설명변수는 오버피팅을 유발하니 몇 개만 남기고 배제함**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`Ridge` : L2 penalty,  `LogisticRegressionCV`의 옵션 `penalty = 'l2'`로 사용가능\n",
    "\n",
    ": coef의 값들을 가중치에 따라 분할하는 수학적 장치.\n",
    "\n",
    "> 패널티 : 상관성이 짙은 설명변수들의 계수값을 제곱한 뒤 합치고(L2-norm을 구하고), 그 값이 0에서 떨어져 있을수록 패널티 부여.\n",
    ">\n",
    "> **불필요한 설명변수는 오버피팅을 유발하니 불필요한 녀석이 없도록 만듦**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270d2f5-4599-412b-a5ee-55c469a7429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.linear_model.Lasso(alpha = float)\n",
    "sklearn.linear_model.LassoCV(alphas = list of floats)\n",
    "## alpha의 스케일이 작음. 0~2 정도\n",
    "\n",
    "sklearn.linear_model.Ridge(alpha = float)\n",
    "sklearn.linear_model.RidgeCV(alphas = list of floats)\n",
    "## alpha의 스케일이 큼. 5e2 ~ 5e10 정도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c077f-6216-498f-8ee8-7c40ee43fd3e",
   "metadata": {},
   "source": [
    "### **11. 선형모형의 적**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3080da0-bd0b-41bc-a627-2d2916feadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.impute\n",
    "import sklearn.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216af48d-405f-4af6-8150-3c52ebb4c5fa",
   "metadata": {},
   "source": [
    "* 결측치의 존재(뭐가 되었든 결측치는 모델이 감지하지 못하니까 직접 처리해줘야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb4bb4-8e25-4b2c-a950-001e32cf56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치를 제거\n",
    "df.info()\n",
    "df.loc[:, df.isna().mean() < 0.5]  ## 결측치가 50% 미만인 열만 선택\n",
    "df.dropna()  ## 결측치가 하나라도 있는 행을 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bfcfbb-21ad-4512-9e1b-e8669dcd99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치를 impute\n",
    "imputr = sklearn.impute.SimpleImputer(strategy = '')\n",
    "imputr.fit_transform(X)\n",
    "imputr.trainsform(XX)  ## 필요한 경우라면 fit_transform. 합쳐서 하면 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fb44e-f3a4-4279-bb68-5243267fbd5f",
   "metadata": {},
   "source": [
    "* 다중공선성의 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e473466-baa3-4fb8-b2df-ee6af6e6e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수 제거\n",
    "X.corr()  ## 설명변수 간 상관계수가 높을 시 직접 제거\n",
    "sns.heatmap(X.corr(), annot = True)\n",
    "\n",
    "## 패널티 계열 사용\n",
    "sklearn.linear_model.Lasso()\n",
    "sklearn.linear_model.Ridge()\n",
    "sklearn.linear_model.LogisticRegressionCV(penalty = , solver = )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df6903-c182-4c29-a7fb-c13cf32d320f",
   "metadata": {},
   "source": [
    "* 반응변수와 관련이 없는 설명변수 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3fb40-fe7a-4541-9914-35fe821a43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수 제거\n",
    "df.corr()\n",
    "sns.heatmap(df.corr(), annot = True)  ## 반응변수와의 상관계수가 낮을 시 직접 제거\n",
    "\n",
    "## 패널티 계열 사용\n",
    "sklearn.linear_model.Lasso()  ## LassoCV(alphas = np.linspace(a, b, n))\n",
    "sklearn.linear_model.LogisticRegressionCV(penalty = 'l1', solver = 'liblinear')\n",
    "## > 필요없는 설명변수는 계수를 0으로 만들어 무력화시킨다.\n",
    "\n",
    "## 더 많은 데이터를 확보...는 설명변수가 하나 늘어날수록 필요한 데이터의 수가 지수적으로 증가해서 어려움..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a0e42-fa75-4490-9499-a2d880bdd838",
   "metadata": {},
   "source": [
    "* 이상치의 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2e605-abdb-41eb-af71-483ed56281e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이상치를 제거하고 분석\n",
    "\n",
    "## 로버스트 선형회귀 계열을 이용\n",
    "\n",
    "## 이상치를 완화시키는 변환을 사용\n",
    "sklearn.preprocessing.PowerTransformer()  ## 조금 더 강제로 정규분포로 전환\n",
    "sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbccc21-d66c-48b9-9880-24815228ec35",
   "metadata": {},
   "source": [
    "* 교호작용의 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71781b3-ec68-4243-90a9-2cbcb02c325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 교호작용이 있는 열끼리 곱함\n",
    "df.assign(interaction = df.X1 * pd.get_dummies(df.X2, drop_first = True))\n",
    "\n",
    "## 교호작용에 영향을 받지 않는 모델 사용\n",
    "sklearn.tree.DecisionTreeRegressor()  ## Linear\n",
    "sklearn.tree.DecisionTreeClassifier()  ## Logistic\n",
    "\n",
    "## 교호작용 판단\n",
    "ggplot(df) + geom_point(aes(x = '설명변수 1', y = '반응변수', color = '설명변수 2'))  ## 연속형인 경우\n",
    "## > 해당 결과에서 색상 별 언더라잉을 그릴 수 있으면, 교호작용이 있다고 판단할 수 있다.\n",
    "df_train.pivot_table(index = '설명변수 1', columns = '설명변수 2', values = '반응변수', aggfunc = 'mean')  ## 범주형\n",
    "## > 해당 결과에서 둘 모두가 바뀌었을 때 평균 차이가 더 크다면, 교호작용이 있을 것으로 예상할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca791bb-3ec0-4c2f-af4d-4c5676b198e2",
   "metadata": {},
   "source": [
    "### **12. 의사결정나무 활용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3aeca-e4d9-4ef7-8c3d-3b8408c808d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd77e4-cecb-46ae-ac7b-b09d5b906825",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다중공선성, 반응변수와 관련이 없는 설명변수, 이상치, 교호작용\n",
    "## 설명변수의 수가 많아질수록 tree계열의 정확도가 Lasso나 Ridge보다 좋아짐.\n",
    "## 적합에 관여한 구간 외의 값이 인풋되면, tree 모형은 그 값을 잘 예측하지 못한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a706c-0f0c-495a-b421-657a47797e19",
   "metadata": {},
   "source": [
    "### **13. 기타 팁**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abee73f-1b64-49e7-977b-69eef40f2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 열에 유니크한 값들이 얼마나 있는지 파악하는 코드\n",
    "{col : len(set(df_train[col])) for col in df_train.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c408e21-8c9c-4de6-864a-7d25ad0e0cc5",
   "metadata": {},
   "source": [
    "## Final Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df1be4-7e40-4f38-8102-c03d9b7a53fd",
   "metadata": {},
   "source": [
    "### **14. 플랏 애니메이션**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c5b74-7df0-4ca4-bfa5-583574862eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0154c6b-38d6-4bee-aa09-a715625df053",
   "metadata": {},
   "source": [
    "* `fig`, `function`, `frame` 이 세 가지 변수가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfa319-bea6-41e9-8a48-69ea30df7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 : create figure\n",
    "fig = plt.figure()\n",
    "\n",
    "## step 2 : define function\n",
    "def func(frame) :\n",
    "    ax = fig.gca()  ## axis를 가져옴\n",
    "    ax.clear()  ## 다음 프레임으로 넘어갈 때 기존 axis를 비워줌\n",
    "    ax.plot()  ## 플로팅(프레임에 따라 변하도록)\n",
    "    ax.set_title()  ## 타이틀 설정 및 레이블링\n",
    "\n",
    "## step 3 : create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig, func, frames = int\n",
    ")\n",
    "\n",
    "## step 4 : output\n",
    "display(IPython.display.HTML(ani.to_jshtml()))  ## 자바스크립트 html로 들여온 것을 IPython으로 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c22529-1369-4058-99be-769e149b6630",
   "metadata": {},
   "source": [
    "### **15. 의사결정나무 작동원리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a224e-aee2-44c0-9b0b-007035db8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import IPython\n",
    "import sklearn.tree\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f15c4-7d8a-4bc4-8908-354a04e336ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.tree.DecisionTreeRegressor(\n",
    "    max_depth = int, ## 1 이상의 정수\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23017681-632d-48a5-aeb7-844202225efb",
   "metadata": {},
   "source": [
    "* `max_depth`에 따른 적합 그래프 애니메이션 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29ef43-f468-473f-8e06-ca089da5ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = [sklearn.tree.DecisionTreeRegressor(max_depth = i+1) for i in range(frame)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced825c-d958-4d46-b886-271815eaf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create figure\n",
    "fig = plt.figure()\n",
    "\n",
    "## create predictr and fitting : 리소스 절감, 명확하게 하려면 func에 삽입할 것\n",
    "predictrs = [sklearn.tree.DecisionTreeRegressor(max_depth = i+1) for i in range(10)]  ## i는 0부터 시작이므로 1을 더해준다.\n",
    "\n",
    "for predictr in predictrs :\n",
    "    predictr.fit(X, y)\n",
    "\n",
    "## define function\n",
    "def func(frame):\n",
    "    ax = fig.gca()\n",
    "    ax.clear()\n",
    "    ax.plot(X, y, 'o', alpha = 0.5, label = 'True')\n",
    "    ax.plot(X, predictr[frame].predict(X), '--', label = 'Predicted')\n",
    "    ax.set_title('max_depth = {}'.format(str(frame+1)))  ## f-string을 사용하면 f'max_depth = {str(frame+1)}'\n",
    "\n",
    "## create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = 10  ## max_depth = 10 까지 시각화\n",
    ")\n",
    "\n",
    "## display\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4cfac3-6b34-4b2e-8a44-cb4206af02f7",
   "metadata": {},
   "source": [
    "* 노드 분할 결정기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1e2e7-b14c-4d2b-8fec-af0f5f3b0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(y, y_hat)  ## predictr.score()와 동일('Regression Model'에서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9a6e8-7e48-4017-b9ae-a80fa5ac9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X, y, c) :\n",
    "    \"\"\"\n",
    "    X와 y, 분할할 구간을 넣어주면 max_depth = 1일 때의 구간에 따른 예측값을 반환하는 함수.\n",
    "    \"\"\"\n",
    "    X = np.array(X).reshape(-1)  ## 1차원으로 깨줌\n",
    "    y = np.array(y)\n",
    "    yhat = y*0  ## 초기값 배정\n",
    "    yhat[X<=c] = y[X<=c].mean()  ## bool list로 슬라이싱\n",
    "    yhat[X>c] = y[X>c].mean()\n",
    "    \n",
    "    return yhat  ## 분할 값이 c일 때의 예측치\n",
    "\n",
    "cuts = np.arange(-5, 15)\n",
    "\n",
    "## create figure\n",
    "fig = plt.figure()\n",
    "\n",
    "## define function\n",
    "def func(frame) :\n",
    "    ax = fig.gca()\n",
    "    ax.clear()\n",
    "    yhat = fit_predict(X, y, cuts[frame])  ## frame번째에 해당하는 분할 값이 들어감\n",
    "    \n",
    "    ax.plot(X, y, 'o', alpha = 0.5, label = 'True')\n",
    "    ax.plot(X, yhat, '--', label = 'Predicted')\n",
    "    ax.set_title(f'c = {cuts[frame]},  R-squared = {round(sklearn.metrics.r2_score(y, yhat), 4)}')  ## 들어가야 할 함수가 많으므로 f-string을 이용했음\n",
    "    ax.legend()\n",
    "\n",
    "## create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = len(cuts)  ## yhat값을 전부 담기 위해서\n",
    ")\n",
    "\n",
    "## display\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04446c86-f0f2-44e8-a65e-1cace758fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최댓값을 찾는 방법\n",
    "cuts = np.arange(-5, 15, 0.001).round(5)\n",
    "scores = np.array([sklearn.metrics.r2_score(y, fit_predict(X, y, c)) for c in cuts])\n",
    "display(pd.DataFrame({'cut':cuts, 'score':scores}).plot.line(x = 'cut', y = 'score', backend = 'plotly'))\n",
    "display(cuts[scores.argmax()])  ## 최댓값인 argument, x의 해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641ce60-d9f9-4850-ace9-06c543c8da62",
   "metadata": {},
   "source": [
    "* `plot_tree` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abffaa1-846b-4ef9-b0ea-1116293c6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import graphviz\n",
    "\n",
    "#-#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12f9d4-2918-4957-874b-2aed1da6d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot_tree를 개별 axe에 삽입\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots(2,1)\n",
    "ax[0].plot(y, y, '--')\n",
    "ax[0].plot(y, predictr.predict(X), 'o', alpha = 0.1)\n",
    "\n",
    "sklearn.tree.plot_tree(\n",
    "    predictr,\n",
    "    max_depth = int,  ## predictr에서의 깊이 이하여야 함\n",
    "    feature_names = X.columns.to_list(),  ## 노드들에 대한 이름을 지정해줌, 순서대로 넣어야 함.\n",
    "    ax = ax[1]  ## 해당 옵션으로 i번째 ax에 삽입이 가능하다.\n",
    ");\n",
    "\n",
    "## dpi를 조절해서 전부 보이게 만드는 방법, 사진이 왕창 커짐\n",
    "fig.suptitle('str')\n",
    "fig.set_dpi(int)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ac4a4-1bc7-4259-bfc4-b91b59ed5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sklearn.tree.export_graphviz(\n",
    "    predictr,\n",
    "    feature_names = X.columns.to_list()\n",
    ")\n",
    "\n",
    "graphviz.Source(g)  ## plot_tree 개체 자체를 조정하는 방법\n",
    "graphviz.Source(g).render('tree', format = 'pdf')  ## 파일로 저장도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984d50b-119c-4667-ac8e-1c4dbf414c78",
   "metadata": {},
   "source": [
    "* 추가 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4dfb2-c08e-4af3-a912-948456636568",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.tree.DecisionTreeRegressor(max_features = int or rate, random_state = int)\n",
    "## 적합 시 최대 몇 개의 설명변수를 사용할 것인지 1 이상의 정수나 비율로 지정한다. fit()할 때마다 결과값이 달라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff12ff8-f1b5-42f2-acca-c7ea67282b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.tree.DecisionTreeRegressor()\n",
    "predictr.fit(sample_weight = 'int list')  ## 몇 번째 값을 얼마나 중요하게 여길 지 그 비중을 입력해준다. 배깅의 핵심 코드이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfd2f5-a83b-46a9-b804-4c2834cdf2c6",
   "metadata": {},
   "source": [
    "### **16. 배깅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b55806-bc91-4443-beda-570ad59620a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "import matplotlib.animation\n",
    "import IPython\n",
    "\n",
    "#-#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaffb3f-a6ca-49d0-8380-70a58de258d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "X = '더미화 한 설명변수열'\n",
    "y = '반응변수열'\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.ensemble.BaggingRegressor()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d093b-1ecf-476f-91d8-3ce4a1318dee",
   "metadata": {},
   "source": [
    "> 기본적으로 부트스트랩한 10개의 샘플을 이용해서 퓨어 트리로 적합한 뒤 그 값들의 평균을 내는 알고리즘이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39215b6a-0432-4e6d-b53f-b2355ca2b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.estimators_  ## 적합한 개별 트리 모듈, predictr.estimators_[i].predict(X)를 하면 그 예측값이 다 다르게 나온다.\n",
    "predictr.estimators_samples_  ## 재표본 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d67cf-f4e9-49ff-aaed-85c959a51bf8",
   "metadata": {},
   "source": [
    "* 내부 모형과 수제 모형 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d232b-bee4-4b36-a176-aaa15807caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create figure\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "## define function\n",
    "def func(frame) :\n",
    "    ax[0].clear()  ## 배깅으로 적합한 predictr\n",
    "    sklearn.tree.plot_tree(\n",
    "        predictr.estimators_[frame],\n",
    "        feature_names = X.columns.to_list(),\n",
    "        max_depth = 1,\n",
    "        ax = ax[0]\n",
    "    )\n",
    "    ax[0].set_title('Bagging Predictor')\n",
    "\n",
    "    ax[1].clear()  ## 기본 의사결정나무로 적합한 predictr\n",
    "    tree = sklearn.tree.DecisionTreeRegressor()\n",
    "    tree.fit(X_arr[predictr.estimators_samples_[frame]], y_arr[predictr.estimators_samples_[frame]])\n",
    "    # tree.fit(X, y, sample_weight = [sum(predictr.estimators_samples_[frame] == i) for i in range(len(predictr.estimators_samples_[0]))])  ## 이게 더 정확하긴 함\n",
    "    sklearn.tree.plot_tree(\n",
    "        tree,\n",
    "        feature_names = X.columns.to_list(),\n",
    "        max_depth = 1,\n",
    "        ax = ax[1]\n",
    "    )\n",
    "    ax[1].set_title('Pure Tree')\n",
    "\n",
    "## create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = 10\n",
    ")\n",
    "\n",
    "## display\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b655a2-5db8-47c3-9578-5355958cfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([tree.predict(X) for tree in predictr.estimators_]).mean(axis = 0)  ## 해당 값은 predictr.predict(X)와 동일하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90daccdb-6348-4ebb-8b74-25e66fea4d7d",
   "metadata": {},
   "source": [
    "* `ensemble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01216151-e776-41ab-a4a4-a115a1506e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(trees, i=None) :\n",
    "    \"\"\"\n",
    "    tree들이 엮여있는 predictr를 입력하면, i번째 트리까지의 평균을 yhat으로 반환하는 함수\n",
    "    \"\"\"\n",
    "    if i is None :\n",
    "        i = len(trees.estimators_)  ## i가 trees의 length를 초과해도 로직 상 문제가 없다.\n",
    "    yhat = np.array([tree.predict(X) for tree in trees.estimators_[:i+1]]).mean(axis = 0)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a80d2-7927-4553-b18d-0f37aba655db",
   "metadata": {},
   "source": [
    "* 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17775510-db04-45d7-84c6-b409cb0eeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize = (13, 3))\n",
    "\n",
    "def func(i) :\n",
    "    for a in ax:\n",
    "        a.clear()\n",
    "\n",
    "    ## step 0 -- data import\n",
    "    ax[0].set_title('Step 0')\n",
    "    ax[0].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "\n",
    "    ## step 1 -- Resampling\n",
    "    ax[1].set_title('Step 1 : ReSampling')\n",
    "    ax[1].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "    ax[1].plot(X_arr[samples[i]], y_arr[samples[i]], 'o', alpha = 0.3)\n",
    "    \n",
    "    ## step 2 -- fitting\n",
    "    ax[2].set_title('Step 3 : Fitting')\n",
    "    ax[2].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "    ax[2].plot(X_arr[samples[i]], y_arr[samples[i]], 'o', alpha = 0.3)\n",
    "    ax[2].plot(X, trees[i].predict(X), '--')  ## 개별 tree의 적합\n",
    "    \n",
    "    ## step 3 -- ensemble\n",
    "    ax[3].set_title('Step 4 : Ensemble')\n",
    "    ax[3].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "    ax[3].plot(X, ensemble(predictr, i), '--', color = 'C1')\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = len(predictr.estimators_features_)\n",
    ")\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46ccb6-a4cd-44db-a21c-06579a50c900",
   "metadata": {},
   "source": [
    "### **17. 랜덤포레스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7b310-e5ba-4280-a9a4-58a54c0f7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e702c7d-8ad6-40b0-8047-97839f3b19cc",
   "metadata": {},
   "source": [
    "* `배깅 + max_features` : 트리들의 다양성 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4af496-3a5a-4719-b187-7de29fbeec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "## step 2\n",
    "predictr = sklearn.ensemble.RandomForestRegressor(\n",
    "    max_depth = 1,\n",
    "    max_features = 1/3  ## parameter를 float으로 지정해줄 경우 비율로 지정됨, 디폴트가 1.0이므로 반드시 지정해줄 것\n",
    ")\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee5006-8e3e-4aeb-9c81-ce645f235c86",
   "metadata": {},
   "source": [
    "* 랜덤포레스트 재현(`predictr.estimators_samples_`같은 거 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec2588-32f2-42f9-9925-a8f4f86a2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## max_features와 random_state가 중점\n",
    "predictr.estimators_  ## 100개의 트리\n",
    "rs = [tree.random_state for tree in predictr.estimators_]  ## 100개의 random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace42b13-6d58-4f8c-ac64-1df861c50a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_forest = [sklearn.tree.DecisionTreeRegressor(max_depth = 1, max_features = 1/3, random_state = r) for r in rs]  ## 100개의 다른 random_state를 갖는 트리 생성(숲)\n",
    "\n",
    "sample = sklearn.ensemble._forest._generate_sample_indices\n",
    "my_index = [sample(random_state = r, n_samples = 1338, n_samples_bootstrap = 1338) for r in rs]  ## 부트스트랩으로 random_state가 일치하는 샘플들의 인덱스를 뽑는다.\n",
    "\n",
    "for idx, tree in zip(my_index, my_forest) :\n",
    "    X_sample, y_sample = X.loc[idx], y.loc[idx]\n",
    "    ## or np.array(X)[idx], np.array(y)[idx]\n",
    "    tree.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70429ed1-a1a3-478b-98c5-80e7669bb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 엄밀한 코드\n",
    "for idx, tree in zip(my_index, my_forest) :\n",
    "    weight = [sum(my_index == i) for i in range(len(my_index))]\n",
    "    tree.fit(X, y, sample_weight = weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75a302-828d-4ba0-8362-1c27017106ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(forest) :\n",
    "    \"\"\"\n",
    "    적합된 트리들을 넣으면 평균을 반환하는 함수\n",
    "    \"\"\"\n",
    "    return np.stack([tree.predict(X) for tree in forest]).mean(axis = 0)\n",
    "\n",
    "ensemble(my_forest) ## predictr.predict(X)와 그 값이 동일해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44223e7-e5d7-4f67-a74e-96f139ff78ba",
   "metadata": {},
   "source": [
    "### **18. 부스팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89114ccf-a4fb-4ede-84f0-94d6827c1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#---#\n",
    "import matplotlib.animation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f647e62-1483-4231-816a-e4c1acd8d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "## step 2\n",
    "predictr = sklearn.ensemble.GradientBoostingRegressor()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "yhat = predictr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b2339-391f-4371-9d06-47eb4d3dc359",
   "metadata": {},
   "source": [
    "* 로우 레벨부터 적합하고(`max_depth`를 낮게 가져감으로써) 잔차를 적합해나가는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae7772-4b4b-4ca7-8b66-08ece9f0966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [t[0] for t in predictr.estimators_]  ## 이중 리스트라 풀어줘야 트리 개체가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226fb0d-4ebc-4a46-8196-ccb8bd72947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 어셈블리 코드\n",
    "def ensemble(trees, i = None) :\n",
    "    if (i is None) or (i+1 > len(trees)) :\n",
    "        i = len(trees)\n",
    "    else :\n",
    "        i = i+1  ## loc하게 되면 그것 다음것까지로 넣어야되니까.\n",
    "    predictions = [trees[j].predict(X) for j in range(i)]\n",
    "    yhat = np.array(predictions[:i]).sum(axis = 0)*0.1 + y.mean()  ## 축의 값들을 가중치를 반영하여 더해야 함.\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cc934-aff3-495c-a221-324e88820ffe",
   "metadata": {},
   "source": [
    "* 적합되는 장면 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ee5a3-0435-4796-b2dc-3be4bb5e02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "plt.close()  ## 쌩 피규어가 콘솔에 안뜨도록 함. 이중으로 뜨는 거 방지, 쓸모없는 거 안나오도록 함\n",
    "\n",
    "def func(frame) :\n",
    "    ax.clear()\n",
    "    ax.plot(X, y, 'o', label = 'RawData')  ## 원자료\n",
    "    ax.plot(X, ensemble(trees, frame), '--', label = 'WeakPredictor (ver ({})'.format(round((frame+1)*0.01, 3)))\n",
    "    ax.legend()\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, func, frames = 100)\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6a517-7f75-4f73-8d4b-6d5d67ac8f76",
   "metadata": {},
   "source": [
    "* 손으로 재현하여 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ede67f-be98-4b9e-9a87-a3b7caf542ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trees = []\n",
    "my_residuals = []\n",
    "\n",
    "res = y - y.mean()  ## 잔차(태초의)\n",
    "\n",
    "## 100번 공부\n",
    "for i in range(100) :\n",
    "    tree = sklearn.tree.DecisionTreeRegressor(max_depth = 3, criterion = 'friedman_mse')\n",
    "    tree.fit(X, res)  ## 아직 적합되지 못한 잔차에 대해서 적합을 함(오버피팅???)\n",
    "    yhat = tree.predict(X)\n",
    "    res = res - yhat*0.1  ## 학습한 것을 다 반영하지 말고 learning_rate만큼만 반영하자. (그래야 다양하게 적합할 수 있음)\n",
    "    my_trees.append(tree)\n",
    "    my_residuals.append(res)\n",
    "\n",
    "## 덜 깊게 적합하는 선에서 잔차를 적합하고, 또 적합하고... 이 과정을 100번 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c192c6-b4fa-44e3-8cd4-620b32f3a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "plt.close()\n",
    "\n",
    "def func(frame) :\n",
    "    for i in range(2) :\n",
    "        for j in range(2) :\n",
    "            ax[i,j].clear()\n",
    "            ax[i,j].plot(X, y, 'o', alpha = 0.5)\n",
    "\n",
    "    ax[0,0].plot(X, ensemble(trees, frame), '--')  ## Boosting Trees\n",
    "    ax[0,1].plot(X, ensemble(my_trees, frame), '--')  ## Pure Trees(직접 적합한 모형)\n",
    "\n",
    "    sklearn.tree.plot_tree(trees[frame], max_depth = 0, feature_names = X.columns.to_list(), ax = ax[1,0])  ## Boosing Trees\n",
    "    sklearn.tree.plot_tree(my_trees[frame], max_depth = 0, feature_names = X.columns.to_list(), ax = ax[1,1])  ## Pure Trees(직접 적합한 모형)\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, func, frames = 100)\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8b795-48af-4473-b3e0-edbe3946eec4",
   "metadata": {},
   "source": [
    "* 과정 별 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2028ed-c533-4dd3-bd5d-19534cb7131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize = (10, 3))\n",
    "plt.close()\n",
    "\n",
    "def func(frame) :\n",
    "    for a in ax :\n",
    "        a.clear()\n",
    "\n",
    "    ax[0].set_title('Step 0')\n",
    "    ax[0].plot(X, y, 'o', alpha = 0.5)\n",
    "    ax[0].plot(X, ensemble(my_trees, frame), '--')\n",
    "    \n",
    "    ax[1].set_title('Step 1 : Residuals')  ## 적합하고 남은 잔차를 계산\n",
    "    ax[1].plot(X, my_residuals[frame], 'o', alpha = 0.5)  ## 잔차 시각화\n",
    "    ax[1].set_ylim(-20,20)\n",
    "    \n",
    "    ax[2].set_title('Step 2 : Fitting')  ## 잔차에 대해 트리로 적합\n",
    "    ax[2].plot(X, my_residuals[frame], 'o', alpha = 0.5)\n",
    "    ax[2].plot(X, my_trees[frame].predict(X), '--')  ## 잔차에 대한 적합선\n",
    "    ax[2].set_ylim(-20,20)\n",
    "    \n",
    "    ax[3].set_title('Step 3 : Update')\n",
    "    ax[3].plot(X, y, 'o', alpha = 0.5)\n",
    "    ax[3].plot(X, ensemble(my_trees, frame), '--', color = 'C1')\n",
    "    ax[3].plot(X, ensemble(my_trees, frame+1), '--', color = 'C3')\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, func, frames = 100)\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c87c98-01bd-4271-8667-1fed197c3e2f",
   "metadata": {},
   "source": [
    "### **19. 평가지표의 이해**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484568c0-6f40-462c-b815-59a5e35100e6",
   "metadata": {},
   "source": [
    "* Confusion Matrix(혼동 행렬) : 멀티클래스나 바이너리 모델만 해당된다\n",
    "\n",
    "||Positive 예측|Negative 예측|\n",
    "|:-:|:-:|:-:|\n",
    "|True 실제|TP(O, O)|FN(O, X)|\n",
    "|False 실제|FP(X, O)|TN(X, X)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8ede-a70a-4e77-9ed7-cb575cf1278e",
   "metadata": {},
   "source": [
    "* `Accuracy`(정확도) : $\\frac{TP+TN}{TP+FP+FN+TN}$\n",
    "> 정답률."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7270a-43f2-403b-b813-64f1f7caccbe",
   "metadata": {},
   "source": [
    "* `TPR`, `Recall`, `Sensitivity` : $\\frac{TP}{TP+TN}$\n",
    "\n",
    "> 실제 1인 사람 중 모형이 1이라고 예측한 사람의 비율(나간 사람 중 찍힌 사람)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553911e-8196-43c3-aa9f-85daa2901ce1",
   "metadata": {},
   "source": [
    "* `Precision` : $\\frac{TP}{TP+FP}$\n",
    "\n",
    "> 모형이 1이라고 예측한 사람 중 실제 1인 사람의 비율(찍힌 사람 중 나간 사람)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f0a2b-e02b-41cf-8bb2-b29915d533d6",
   "metadata": {},
   "source": [
    "* `F1-score` : `Recall`과 `Precision`의 조화평균\n",
    "\n",
    "> 둘 다 어느정도 높은 지 알려주는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb2072-6808-4eb1-826e-11ffb3d42911",
   "metadata": {},
   "source": [
    "* `Specificity`(특이도) : $\\frac{TN}{TN+FP}$\n",
    "\n",
    "> 실제 0인 사람 중 모형이 0이라고 예측한 사람의 비율(안 나간 사람 중 안찍힌 사람, ~안 중요함~)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a478d-dbdf-42f7-83f5-8e1c897dc561",
   "metadata": {},
   "source": [
    "* `FPR` : $\\frac{FP}{FP+TN}$\n",
    "\n",
    "> 실제 0인 사람 중 모형이 1이라고 예측한 사람의 비율(안 나간 사람 중 찍힌 사람)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8ca2c-d9e8-4537-aa5c-315dc7b431b4",
   "metadata": {},
   "source": [
    "* `ROC curve` : $x$축을 `FPR`로, $y$축을 `TPR`로 그린 커브\n",
    "\n",
    "> 아래 면적을 평가지표로 `AUC score`라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bedf1-f16c-4cc7-8995-a9c410eb619d",
   "metadata": {},
   "source": [
    "* 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a84f9-a8da-4538-b4d4-bac611dc6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505ec30-aa39-48e3-a0ce-bfb4f1c8b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp), (fn, tp) = sklearn.metrics.confusion_matrix(y, yhat)  ## (tn, tp), (fn, tp) 순서로 지정된다.\n",
    "## 딱 반바퀴 뒤집으면 위의 혼동 행렬 형식과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069df729-062e-4e47-b448-270f73b19a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "sklearn.metrics.accuracy_score(y, yhat)  ## 둘다 동일한 수치 산출\n",
    "\n",
    "TPR = recall = sensitivity = tp/(tp+fn)\n",
    "sklearn.metrics.recall_score(y, yhat)  ## 역시 둘다 동일함\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "sklearn.metrics.precision_score(y, yhat)  ## 또 같음\n",
    "\n",
    "FPR = fp/(fp+tn)  ## 이건 따로 모듈이 없음\n",
    "\n",
    "sklearn.metrics.roc_auc_score(y, yhat)  ## auc_score, 어떻게 나오는 거야?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f3448-be00-4449-9ddf-33bb56cd4526",
   "metadata": {},
   "source": [
    "### **20. Autogluon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffac93d-f81e-46d5-8c41-e0bb7e3e08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autogluon.eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f11260-a12e-41e8-ae06-d0540051c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics  ## 스코어 계산??\n",
    "\n",
    "import pickle  ## 데이터 압축해서 output하려고 가져오신듯, 여기선 안씀.\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import autogluon.eda.auto as auto  ## !pip install autogluon.eda 가 필요할 수 있다.\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea629e1f-03f6-41e4-a4d5-ca2a1f34d3d1",
   "metadata": {},
   "source": [
    "* 적합 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314fd91-7fe6-4ab0-b391-34d8fa92f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 -- pass 필요없다!! 더미변수 설정도 안해도 된다.\n",
    "## step 2\n",
    "predictr = TabularPredictor(label = '반응변수열')  ## target variable의 column name을 넣어줌\n",
    "## step 3\n",
    "predictr.fit(df_train, num_gpus = 1, verbosity = False)  ## X, y로 넣을 필요도 없음. gpu 알아서 쓰긴 하는데 몇 개 쓸건지 명시 가능. 과정 길게 나열 안하도록 설정 가능\n",
    "## step 4\n",
    "yhat = predictr.predict(df_train)  ## X만 넣을 필요도 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6b6ee-6a72-4e93-9fc4-dfa30bffb631",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.leaderboard(silent = True)  ## silent = True로 데이터프레임만 볼 수 있음, 안그러면 미가공된 텍스트 테이블을 함께 띄움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e098bc-a391-4ba4-80c7-74d55a341dde",
   "metadata": {},
   "source": [
    "> 최강 모형을 사용하여 알아서 적합해주고, 모든 결과를 종합하여 하나의 모형을 만들고 이로 적합하기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72513b44-97e3-4247-94ab-2247256577b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.predict(label = '반응변수열', model = '원하는 모델의 이름(리더보드에서 긁어오셈)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d9bfa-32d8-4fea-a299-0150723d126b",
   "metadata": {},
   "source": [
    "* `eda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a52a7-f689-4a29-9432-be4ff2f25241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 반응변수 y에 대한 분석(중요도 낮음)\n",
    "auto.target_analysis(\n",
    "    train_data = df_train,\n",
    "    label = '반응변수열',\n",
    "    fit_distributions = False  ## y의 분포가 어떨 지 예상해주는 옵션인데, 쓸모없다고 하신다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68750265-7b58-4c9e-be8c-40d0fab22a38",
   "metadata": {},
   "source": [
    "> 설명변수와의 상관계수가 임의로 0.5보다 아래인 것은 히트맵으로 내놓지도 않고, 여러모로 한계가 뚜렷한 기능이다. 해당 과정은 직접 수행하는 것이 더 좋다.\n",
    ">\n",
    "> 회귀모형의 경우 산점도와 회귀직선을, 바이너리 모형의 경우 히스토그램을 내놓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55a353-4bdf-4b3b-af96-fc09cb18ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap((pd.get_dummies(df_train, drop_first = True)*1).corr(), annot = True)  ## 1을 곱해줘야 프로그램이 인식하기 편하다. 오류가 발생하는 대부분의 경우 시도해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02395759-8d05-4fdd-a6d0-6b7fffed5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 빠른 설명변수에 대한 정보 파악\n",
    "auto.quick_fit(\n",
    "    train_data = df_train,\n",
    "    label = '반응변수열',\n",
    "    show_feature_importance_barplots = True  ## 말그대로 설명변수 간 중요도를 쉽게 파악할 수 있다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c8c89-e4b4-406a-8cde-710dbbcc38e1",
   "metadata": {},
   "source": [
    "> 잔차그림, 간단한 모형으로 적합했을 때의 설명변수의 중요도를 알아낼 수 있다. 적합했을 때 모호한 관측치나 오차가 큰 관측치를 추려주기도 한다. 보다 정밀한 eda를 위해서는 직접 데이터 구조를 뜯어봐야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d4e37-0b0e-4887-97e8-57c3d2b474f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.explain_rows(\n",
    "    train_data = df_train,\n",
    "    model = predictr,  ## Autogluon으로 적합한 predictor를 넣어주면 된다.\n",
    "    rows = df_train.iloc[[0]],  ## 설명변수로 구성된 열을 그대로 넣어준다. 해당 데이터에 대한 예측을 수행하고 왜 그 값이 나왔는 지 설명해준다.\n",
    "    display_rows = True,  ## 입력한 데이터를 띄운다. 바로 위에 그거\n",
    "    plot = 'waterfall'  ## 이 형식이 보기에 깔끔하다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac1267-4a0b-40ff-bdd7-b22f883526a9",
   "metadata": {},
   "source": [
    "> 결측치가 있으면 평균이나 최빈값으로 예측하지 않고 하나의 값이라 여기고 노드를 나눈다.\n",
    ">\n",
    "> 이상치가 있어도 해당 구간에서 노드를 따로 구성함으로써 오차를 줄인다.\n",
    ">\n",
    "> 쓸모없는 데이터는 트리식 모형의 특성으로 인해 해당 열들의 중요도가 적어 오버피팅 문제도 해결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1961a4-1ad6-4e93-8d5b-8d7c6934fc9a",
   "metadata": {},
   "source": [
    "`-` 피쳐 엔지니어링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab2bba-0c82-4f31-ba89-97ffdc28c070",
   "metadata": {},
   "source": [
    "시계열로 적합하지 않을 것이라면 해당 열을 삭제(또는 가용할 수 있는 정보만 뽑아내고 제거, 예를 들면 요일이라거나, 휴일이라거나...)\n",
    "\n",
    "시각화를 계속하여 적합이 잘 되었는지 비교하기 위해 적합 및 그래프 생성 함수를 지정해주면 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eeac4a-a96f-4381-9035-beca7a8c95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(df_train_featured, df_test_featured) :\n",
    "    ## step 1 : pass -- 애초에 정리된 데이터프레임을 인풋값으로 넣어야 함\n",
    "    ## step 2\n",
    "    predictr = TabularPredictor(label = 'count', verbosity = False)\n",
    "    ## step 3\n",
    "    predictr.fit(df_train_featured)\n",
    "    ## step 4\n",
    "    yhat = predictr.predict(df_train_featured)\n",
    "    yyhat = predictr.predict(df_test_featured)\n",
    "    ## display\n",
    "    display(predictr.leaderboard())\n",
    "    return yhat, yyhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d3f80-2a99-4f40-8a31-82a4475cc50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(yhat, yyhat) :\n",
    "    df = pd.concat([df_train, df_test]).assign(datetime = lambda _df : _df.datetime.apply(pd.to_datetime))\\\n",
    ".assign(count_hat = yhat.tolist() + yyhat.tolist(), dataset_type = ['train']*len(yhat) + ['test']*len(yyhat)).reset_index(drop = True)\n",
    "    ## 예측치를 리스트로 먹여서 합쳐준다. 유형을 명시한다. seaborn의 버그로 인해 인덱스를 초기화해줘야 정상작동한다.\n",
    "    sns.lineplot(\n",
    "        df.sort_values('datetime')[:(24*28)], ## 28일까지의 자료만 시각화\n",
    "        x = 'datetime', y = 'count',  ## 실제 관측치를 표기\n",
    "        hue = 'dataset_type', linestyle = '--',\n",
    "        lw = 0.8\n",
    "    )\n",
    "    \n",
    "    sns.lineplot(\n",
    "        df.sort_values('datetime')[:(24*28)],\n",
    "        x = 'datetime', y = 'count_hat',  ## 이전 + 이후 예측치를 표기\n",
    "        hue = 'dataset_type',  ## 이전과 이후를 색상으로 구분\n",
    "        lw = 3, alpha = 0.5\n",
    "    )\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8,2)  ## 사이즈 조절\n",
    "    plt.xticks(rotation = 15);  ## x축 눈금 회전시키기\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2349c-debe-424c-9fba-928dbfaad2aa",
   "metadata": {},
   "source": [
    "<span style='background-color:red'>제한적</span> : 제출 횟수가 자유롭다면 제출까지 함수로 지정해주면 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1463369-9238-4c2b-8dc9-31a19af8897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(yyhat) :\n",
    "    submission['count'] = yhat\n",
    "    submission['count'] = submission['count'].apply(lambda x : x if x>0 else 0)  ## 예측값이 양수에서 형성될 경우 넣어야 하는 코드이다.\n",
    "    submission.to_csv('submission.csv', index = False)\n",
    "    !kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"Message\"\n",
    "    !rm submission.csv\n",
    "\n",
    "def auto(df_train_featured, df_test_featured) :\n",
    "    \"\"\"\n",
    "    피쳐 엔지니어링 된 데이터를 넣으면 적합부터 시각화, 제출까지 수행하는 코드\n",
    "    \"\"\"\n",
    "    yhat, yyhat = fit_predict(df_train_featured, df_test_featured)\n",
    "    plotting(yhat, yyhat)\n",
    "    submit(yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33aebee-11f4-4965-a24e-5c3424a37d57",
   "metadata": {},
   "source": [
    "* 시계열 정보에서 빨아먹을 수 있는 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18256868-ed34-437e-817a-159b0805e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_featured = df_train.copy()\n",
    "df_test_featured = df_test.copy()\n",
    "\n",
    "df_train_featured = df_train_featured.drop(['casual', 'registered'], axis = 1)  ## 안겹치는 거 제거\n",
    "\n",
    "df_train_featured.datetime = pd.to_datetime(df_train_featured.datetime)\n",
    "df_test_featured.datetime = pd.to_datetime(df_test_featured.datetime)\n",
    "\n",
    "## 시간 정보\n",
    "df_train_featured['hour'] = df_train_featured['datetime'].dt.hour\n",
    "df_test_featured['hour'] = df_test_featured['datetime'].dt.hour\n",
    "\n",
    "## 요일 정보\n",
    "df_train_featured['weekday'] = df_train_featured['datetime'].dt.weekday\n",
    "df_test_featured['weekday'] = df_test_featured['datetime'].dt.weekday\n",
    "\n",
    "## 이제 쓸모없는 변수이니 드롭\n",
    "df_train_featured = df_train_featured.drop(['datetime'], axis = 1)\n",
    "df_test_featured = df_test_featured.drop('datetime', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfedc8-5e66-4585-afd2-484f069ca261",
   "metadata": {},
   "source": [
    "* 변수 간 상관계수를 파악하여 너무 낮은 것은 드롭해줄 수 있다. 이 경우 범주형 자료를 드롭할 때 주의해야 하는데, 요일을 0~6의 값으로 저장하였다면 이것이 선형 관계로 착각될 수 있기에 상관계수 해석이 어렵다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56fd65-d2f2-4105-9ec4-05836b1e641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train_featured.set_index('count').reset_index().corr(), vmin = -1, cmap = 'bwr', annot = True)\n",
    "## 범주형 자료의 경우 시각화를 해보고 제외 여부를 결정해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943714a-4a8c-46a6-ae6e-017041e14b18",
   "metadata": {},
   "source": [
    "* 숫자로 되어있는 범주형 자료를 더미화하는 것 : 트리 계열 모델의 경우 어차피 노드로 분할시키기 때문에 큰 영향을 미치지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ddff1-7f06-427a-8070-178dcf7f67fc",
   "metadata": {},
   "source": [
    "히트맵을 그렸을 때 설명변수 간 너무 상관관계가 짙다면, 다중공선성의 문제 때문에 둘 중 하나를 제거해야 함. 이 경우 둘다 적합을 해보고 스코어가 높은 쪽을 택하거나 반응변수와의 상관계수가 높은 쪽을 택함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bdf849-2baf-4086-9f5f-0de964450f5a",
   "metadata": {},
   "source": [
    "* 설명변수나 반응변수에 특정한 변환을 취할 경우 모형이 개선될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468dd943-6138-4fc2-924f-6b176129d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfomr = sklearn.preprocessing.PowerTransformer(method = 'box-cox')  ## 박스콕스 변환, 루트와 로그 변환 절충안임. 양수일 때 사용, 데이터에 음수가 포함될 경우 디폴트로\n",
    "count2 = transfomr.fit_transform(df_train_featured[['count']]).reshape(-1)  ## 변환을 시행한 y값들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194068b-fcca-4373-809b-b9b30111b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 2\n",
    "predictr = TabularPredictor(label = 'count')\n",
    "\n",
    "## step 3\n",
    "predictr.fit(df_train_featured.assign(count = count2))  ## 변환한 값 할당\n",
    "\n",
    "## step 4\n",
    "yhat = predictr.predict(df_train_featured.assign(count = count2))  ## 마찬가지로 변환한 값을...\n",
    "yyhat = predictr.predict(df_test_featured)\n",
    "\n",
    "yhat = transfomr.inverse_transform(yhat.to_frame()).reshape(-1)  ## 역변환, 예상 시 나온 값이 시리즈 형태이므로 데이터프레임 폼으로 바꿔줘야 함\n",
    "yyhat = transfomr.inverse_transform(yyhat.to_frame()).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818752f6-cada-49ff-b2cf-81c7ae596897",
   "metadata": {},
   "source": [
    "> 적절한 변환을 했을 때 모형이 개선될 수 있다. 만약 데이터 개형이 낮은 값에 몰려있고, 높은 값에 적은 형태라면...(약간 지수함수 모양) 해당 변환이 효과가 있을 것(약간 정규분포 모양으로 바꿔줌.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e07d6c-00e2-4372-ae63-a7365e2ca600",
   "metadata": {},
   "source": [
    "### **21. 시계열 자료 분석**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfdd735-d276-435c-b2e7-fef24ab2396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5e7222-53fa-4b8f-91d8-4bc7e4b8660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor  ## TimeSeries 분석에 필요\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c46c5-00d4-4a53-971c-fade970bdd47",
   "metadata": {},
   "source": [
    "* `date`에 해당하는 정보를 가진 열의 자료 형식을 `pandas.datetime`으로 변경해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8efbcbae-c05b-473f-8dd0-d8ec1edee43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>주가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">삼성전자</th>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>72600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       주가\n",
       "item_id timestamp        \n",
       "삼성전자    2023-12-07  72600\n",
       "        2023-12-08  72800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 범주가 하나인 시계열 자료\n",
    "df1 = pd.DataFrame({'시간':['2023-12-07','2023-12-08'], '종목':['삼성전자']*2, '주가':[72600, 72800]})\n",
    "\n",
    "ts1 = TimeSeriesDataFrame(\n",
    "    data = df1,\n",
    "    static_features = None,  ## 아직은 퓨어하다.\n",
    "    id_column = '종목',  ## item_id에 해당하는 열 이름\n",
    "    timestamp_column = '시간'  ## 타임 데이터셋\n",
    ")\n",
    "\n",
    "ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0607408d-548f-43cf-88a0-77cc623fe8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>주가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">삼성전자</th>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>72600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">카카오</th>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>51700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>51600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       주가\n",
       "item_id timestamp        \n",
       "삼성전자    2023-12-07  72600\n",
       "        2023-12-08  72800\n",
       "카카오     2023-12-07  51700\n",
       "        2023-12-08  51600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 범주가 여러개인 시계열 자료\n",
    "df2 = pd.DataFrame({'시간':['2023-12-07','2023-12-08']*2, '종목':['삼성전자']*2+['카카오']*2, '주가':[72600, 72800, 51700, 51600]})\n",
    "\n",
    "ts2 = TimeSeriesDataFrame(\n",
    "    data = df2,\n",
    "    static_features = None,\n",
    "    id_column = '종목',\n",
    "    timestamp_column = '시간'\n",
    ")\n",
    "\n",
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b18ffa4-7184-41a0-b3b3-8dd7355f88d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'타임 시리즈 데이터'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시간</th>\n",
       "      <th>종목</th>\n",
       "      <th>주가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>72600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>카카오</td>\n",
       "      <td>51700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>카카오</td>\n",
       "      <td>51600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           시간    종목     주가\n",
       "0  2023-12-07  삼성전자  72600\n",
       "1  2023-12-08  삼성전자  72800\n",
       "2  2023-12-07   카카오  51700\n",
       "3  2023-12-08   카카오  51600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'고정된 피쳐 데이터'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목</th>\n",
       "      <th>특징1(기업성격)</th>\n",
       "      <th>특징2(사원수)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자</td>\n",
       "      <td>제조</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>카카오</td>\n",
       "      <td>IT</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     종목 특징1(기업성격)  특징2(사원수)\n",
       "0  삼성전자        제조       500\n",
       "1   카카오        IT        25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>주가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">삼성전자</th>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>72600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">카카오</th>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>51700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>51600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       주가\n",
       "item_id timestamp        \n",
       "삼성전자    2023-12-07  72600\n",
       "        2023-12-08  72800\n",
       "카카오     2023-12-07  51700\n",
       "        2023-12-08  51600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 고정된 피쳐 데이터가 포함된 경우\n",
    "df2 = pd.DataFrame({'시간':['2023-12-07','2023-12-08']*2, '종목':['삼성전자']*2+['카카오']*2, '주가':[72600, 72800, 51700, 51600]})\n",
    "df3 = pd.DataFrame({'종목':['삼성전자','카카오'],'특징1(기업성격)':['제조','IT'],'특징2(사원수)':[500,25]})  ## static_features data\n",
    "display('타임 시리즈 데이터', df2, '고정된 피쳐 데이터', df3)\n",
    "#---#\n",
    "ts23 = TimeSeriesDataFrame(\n",
    "    data = df2,\n",
    "    static_features = df3,  ## 고정된 피쳐 데이터, 회사의 특징과 규모(fixed), 온도 예측이라면 위도와 경도, 해발고도나 기후 등.\n",
    "    id_column = '종목',\n",
    "    timestamp_column = '시간'\n",
    ")\n",
    "\n",
    "ts23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252701f3-f4da-4185-9e2c-450032ae9fba",
   "metadata": {},
   "source": [
    "> 외관상으로는 차이가 없으나, 실제로는 해당 특징들이 고려되어야 한다. ~근데 차이 없는 건 아마 하나씩밖에 없어서가 아닐까...?~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35db3a8-a52b-4ce2-ba0a-850c35ad216d",
   "metadata": {},
   "source": [
    "* 적합 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747562b-e3c7-42d9-877a-3cf8a196f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 : data\n",
    "ts_train = TimeSeriesDataFrame(\n",
    "    data = df_train,\n",
    "    static_features = None,  ## 다른 정보 없음(지명이나, 위도나, 지리적 특성이나...)\n",
    "    id_column = 'item_id',  ## 딱히 구분이 없더라도 할당하여 지정해줘야 함, mean이나 sum이나... 어거지로 만들어 주자.\n",
    "    timestamp_column = 'date'\n",
    ")\n",
    "\n",
    "## step 2 : create predictr\n",
    "predictr = TimeSeriesPredictor(\n",
    "    target = 'temp',  ## 예측하고 싶은 것, TabularPredictor의 label옵션과 동일\n",
    "    known_covariates_names = None,  ## 미래에 예상 가능한 정보, 휴일이라던가, 요일이라던가, 기온 습도 등\n",
    "    prediction_length = len(df_test),  ## 앞으로 얼마만큼 예측하고 싶은지\n",
    "    freq = 'D'  ## 주기. 'D' : Day나 'H' : Hour를 주로 사용\n",
    ")\n",
    "\n",
    "## step 3 : fitting\n",
    "predictr.fit(ts_train, time_limit = 50)  ## TimeSeiesDataFrame이 들어가야 한다. 더 빠른 적합 결과 산출을 원한다면 time_limit을 설정해보자.\n",
    "\n",
    "## step 4 : predict\n",
    "predictions = predictr.predict(ts_train)  ## predictions은 데이터프레임 형태로 나오며, 추정값 및 구간 추정치를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abd5aa-d9d0-4e69-971d-54d55a26562e",
   "metadata": {},
   "source": [
    "* 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3b03d-668d-46de-bc11-6015d9d76c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_train.date, df_train.temp, label = 'observed')  ## 실제 데이터\n",
    "plt.plot(df_test.date, df_test.temp, color = 'gray', alpha = 0.5, label = 'future value')  ## 미래 데이터\n",
    "plt.plot(df_test.date, predictions['mean'], color = 'C1', label = 'estimated')  ## 미래 예측(모델 사용)\n",
    "plt.fill_between(df_test.date, predictions['0.1'], predictions['0.9'], color = 'C1', alpha = 0.2)  ## 두 값 사이를 채우는 그래프, 신뢰구간 느낌으로 표시\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8449ef2-e7b0-4412-9aa7-230aa05ae195",
   "metadata": {},
   "source": [
    "`-` 통계학과에서 배우는 시계열 분석 : **주식 시계열??**\n",
    "\n",
    "* 주식에 대한 시계열 자료 : 시간별 독립인 듯 하지만, 사실은 독립이 아닌 자료! (오차항이 독립이 아니다!!)\n",
    "    * 원래 오차항은 독립이여야 한다...(회귀분석의 가정) 주식 시계열은 비합리적인 관측자료가 됨.\n",
    "    *  원래 회귀분석에서 다루는 세팅은... `관측자료 = 정보 + 오차`이다. 이를 시계열로 바꿔 표현하면...**$$주식시계열자료 = 합리적 정보 + 오차 = 합리적 정보 + 기세 + 독립오차$$**\n",
    "      가 된다.\n",
    "<br>\n",
    "\n",
    "* 통계학과에서 배우는 시계열모형은 '기세'를 모델링하는 것이다. 즉, 비합리적인 오차항을 모델링하는 것이다!\n",
    "\n",
    "    * 1시점 전의 기세에 얼마나 영향을 강하게 받는가? : AR(1) 모형의 계수값 결정\n",
    "    * p시점까지의 기세에 얼마나 영향을 강하게 받는가? : AR(p) 모형의 계수값 결정... 이 경우 학습할 파라미터가 너무 많다!\n",
    "      > 그런데 AR(p)와 비슷한 효과를 주고 파라미터를 더 적게 가지는 MA(q), ARMA(p, q)와 같은 모형이 존재함... 따라서 아주 먼 시점의 기세까지 분석해야 한다면(장기까지 분석해야 한다면) ARMA(p, q)를 적합하는 것이 유리함.\n",
    "    * 트렌드와 계절성을 가지는 시계열 자료는 기세를 모델링하기 어려운데...?\n",
    "      > 트렌드를 제거할 수 있는 ARIMA, SARIMA등이 있다.\n",
    "    * 기세의 변동성이 시간에 따라 달라진다면 어쩌지...?(이분산성)\n",
    "      > ARCH, GARCH등을 사용\n",
    "\n",
    "* 합리적정보 : 시계열분석에서 합리적정보(주어진 상황에서의 평균에 대한 정보)는 `static_features`, `known_covariates`에 포함되어 있다.\n",
    "\n",
    "`-` 장기 예측\n",
    "\n",
    "* 장기 예측은 합리적 정보를 잘 추정하는 것이 중요하며, 이는 기세를 모델링하는 것과는 별 상관이 었다. 따라서 시계열로 장기예측을 한다? 다른 방법을 사용하는 게 더 좋음..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e69584-00f8-476f-a3c9-ebc2500b1a29",
   "metadata": {},
   "source": [
    "**자료 형식이 시계열이라고 해서 무작정 시계열로 분석하는 것만이 정답이 아니다. 피쳐 엔지니어링을 통해 회귀문제로 적합하는 것이 적절할 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d9600-9d1c-4311-b417-c885e05025a6",
   "metadata": {},
   "source": [
    "### **22. Autogluon | 하이퍼 파라메터 튜닝**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222bd506-21ed-4774-8ad5-844c001499cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install autogluon.multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e8e9d-dc26-4581-a72f-36101ce0c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from autogluon.common import space\n",
    "\n",
    "import IPython\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba0e0f-5442-4085-845d-88fd139fbe38",
   "metadata": {},
   "source": [
    "`predictr.fit??`\n",
    "\n",
    "```\n",
    "hyperparameters = {\n",
    "                    'NN_TORCH': {},\n",
    "                    'GBM': [\n",
    "                        {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
    "                        {},\n",
    "                        'GBMLarge',\n",
    "                    ],\n",
    "                    'CAT': {},\n",
    "                    'XGB': {},\n",
    "                    'FASTAI': {},\n",
    "                    'RF': [\n",
    "                        {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "                        {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "                        {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}},\n",
    "                    ],\n",
    "                    'XT': [\n",
    "                        {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "                        {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "                        {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}},\n",
    "                    ],\n",
    "                    'KNN': [\n",
    "                        {'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}},\n",
    "                        {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}},\n",
    "                    ],\n",
    "                }\n",
    "```\n",
    "\n",
    "> 디폴트로 들어가 있는 하이퍼파라메터 딕셔너리. 해당 값을 조정하여 하이퍼파라미터 및 적합할 모델 선택이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe559790-7bc2-4c18-a6f0-4ec781f7e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr= TabularPredictor(label='count',verbosity=False)\n",
    "\n",
    "## 리스트에 포함된 딕셔너리 하나 당 모형 하나라고 보면 된다.\n",
    "hp = {\n",
    "    \"NN_TORCH\": {},\n",
    "    \"GBM\": [\n",
    "        {\"extra_trees\": True, \"ag_args\": {\"name_suffix\": \"XT\"}},\n",
    "        {},\n",
    "        \"GBMLarge\"\n",
    "    ],\n",
    "    \"CAT\": {},\n",
    "    \"XGB\": {},\n",
    "    \"FASTAI\": {},\n",
    "    \"RF\": [\n",
    "        {\"criterion\": \"gini\", \"ag_args\": {\"name_suffix\": \"Gini\", \"problem_types\": [\"binary\", \"multiclass\"]}},  ## 분류 모형에서만 작동\n",
    "        {\"criterion\": \"entropy\", \"ag_args\": {\"name_suffix\": \"Entr\", \"problem_types\": [\"binary\", \"multiclass\"]}},\n",
    "        {\"criterion\": \"squared_error\", \"ag_args\": {\"name_suffix\": \"MSE\", \"problem_types\": [\"regression\"]}}  ## 회귀 모형에서만 작동\n",
    "    ],\n",
    "    \"XT\": [\n",
    "        {\"criterion\": \"gini\", \"ag_args\": {\"name_suffix\": \"Gini\", \"problem_types\": [\"binary\", \"multiclass\"]}},\n",
    "        {\"criterion\": \"entropy\", \"ag_args\": {\"name_suffix\": \"Entr\", \"problem_types\": [\"binary\", \"multiclass\"]}},\n",
    "        {\"criterion\": \"squared_error\", \"ag_args\": {\"name_suffix\": \"MSE\", \"problem_types\": [\"regression\"]}}\n",
    "    ],\n",
    "    \"KNN\": [\n",
    "        {\"weights\": \"uniform\", \"ag_args\": {\"name_suffix\": \"Unif\"}},\n",
    "        {\"weights\": \"distance\", \"ag_args\": {\"name_suffix\": \"Dist\"}}\n",
    "    ]\n",
    "}\n",
    "predictr.fit(\n",
    "    df_train_featured,\n",
    "    hyperparameters = hp ## 직접 지정해줄 수 있음\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835f827-e354-4487-a88c-1e67b845727e",
   "metadata": {},
   "source": [
    "`-` 각 모형들이 뭔지, 하이퍼파라메터를 넣는 방법은 뭔지 알아보려면?\n",
    "\n",
    "* ref: https://auto.gluon.ai/0.8.1/api/autogluon.tabular.models.html\n",
    "\n",
    "* LightGBM model: https://lightgbm.readthedocs.io/en/latest/\n",
    "\n",
    "* CatBoost model: https://catboost.ai/\n",
    "\n",
    "* XGBoost model: https://xgboost.readthedocs.io/en/latest/\n",
    "  \n",
    "* Random Forest model (scikit-learn): https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* Extra Trees model (scikit-learn): https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier\n",
    "* Linear model (scikit-learn): https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964b866-3d88-4a44-a435-ecf997d7fd63",
   "metadata": {},
   "source": [
    "* 적합된 모형의 `predictr`를 뜯어보면 파라미터 값을 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa231861-7e21-4bc0-97db-06ba8306588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.info()['model_info']['RandomForestMSE']['hyperparameters']  ## 'RandomForestMSE'에 대한 하이퍼파라메터를 얻고자 할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844a2b2-59de-47a4-a3e2-3276157207c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이런 딕셔너리를 넣어서 파라메터에 따른 스코어를 확인 및 비교할 수도 있다.\n",
    "{'RF' : [ {\"criterion\": \"squared_error\", \"n_estimators\":i, \"max_leaf_nodes\":j, \"ag_args\": {\"name_suffix\": f\"({i},{j})\"}} for i in [300,400,500] for j in [10000,15000]]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
