{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d50df5-bcd4-49d1-a13c-4fc8df4ddd8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Midterm Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81fcd3-580b-4406-b44b-9fa75d321662",
   "metadata": {},
   "source": [
    "### **1. Analysis and Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd608422-33f4-4a2a-89e0-df8a4d36778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## 왠만해선 그냥 sklearn과 연관되게 직접 import하자..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2bfdf-8df6-4154-800c-4bea66616c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('file derectort')  ## csv 데이터를 DataFrame으로 읽어온다. 직접 입력 또는 간접(.) 입력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172ea5a-0fde-42f3-84dc-622944ef2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file name', index = bool)  ## DataFrame을 현재 디렉토리에 csv 파일로 저장한다. index = False로 지정 시 인덱스를 누락시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4743be8-382c-43a7-af09-36f53b4592a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df)  ## DataFrame의 범주형 자료를 포함한 열을 더미변수로 만들어준다. 회귀에 유리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb20f23-083c-45a4-84c9-c1a9fb73955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators = int, max_depth = int, random_state = int)  ## 뭔진 모르겠지만 아무튼 추정하는 모델이다. predictr에 저장하여 predictr.fit(X, y)해주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d1996-a924-4860-aa66-ab4fb5d8fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis cycle, 분석 과정\n",
    "##----1. data----\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X = train.loc[:, features]\n",
    "y = train.loc[:, target]\n",
    "XX = test.loc[: features]\n",
    "##yy = test.loc[:, target] ## 보통 주어지지 않음\n",
    "\n",
    "##----2. predictor----\n",
    "predictr = ...model...\n",
    "\n",
    "##----3. fitting----\n",
    "predictr.fit(X, y)\n",
    "predictr.score(X, y)  ## or another method\n",
    "\n",
    "##----4. submission----\n",
    "test.assign(response = predictr.predict(XX)).loc[:, response].to_csv('file name', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824385c6-963b-4cdf-8aaf-8ecd990c9d89",
   "metadata": {},
   "source": [
    "### **2. autogluon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f8366b-eb58-409f-9624-e561c323e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !pip install autogluon  ## colab or kaggle notebook. 이미 환경이 구성되어 있다면 필요없음.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e89b5c-de31-46ad-a5d0-5a49026fa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularDataset('file derectory')  ## pd.read_csv()와 비슷한 코드라고 보면 된다. 실제로 해당 개체를 다루는 방식이 거의 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb2df1-1e4f-4c85-9576-beb422c5f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis cycle\n",
    "\n",
    "#----1. data----\n",
    "train = TabularDataset('train.csv directory')\n",
    "test = TabularDataset('test.csv directory')\n",
    "\n",
    "#X = train.drop([반응변수 열], axis = 1)\n",
    "#y = train[반응변수 열]\n",
    "#XX = test.drop([반응변수 열], axis = 1)\n",
    "#상기 과정이 필요없다.\n",
    "\n",
    "#----2. create predictor----\n",
    "predictr = TabularPredictor(반응변수 열)\n",
    "\n",
    "#----3. fitting----\n",
    "predictr.fit(train)  ## 다른 선형회귀에선 설명변수와 반응변수를 나눠줬지만, 여기선 한번에 입력했다. 이미 predictr에 무엇이 반응변수인지 지정해줬기 때문이다.\n",
    "(train[반응변수 열] == predictr.predict(X)).mean()  ## 몇 퍼센트가 맞는 지 산출해준다. score에 해당한다.\n",
    "\n",
    "#----4. submittion----\n",
    "test.assign(반응변수 열 = predictr.predict(XX)).loc[:, 제출에 필요한 열].to_csv(디렉토리, index = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba18c09-96db-4e1c-a9e8-97d6be659628",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.leaderboard()  ## fitting을 마친 predictr가 사용한 모델들의 성능 순위가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6ecdc0-382d-4788-8ab5-aaf9be111f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# 유사한 정보를 가지고 있는 여러 열들을 하나로 합치면 더 좋은 결과가 나온다(다중 공선성 해결 등)\n",
    "train.assign(Fsize = train.Sibsp + train.Parch).drop(['Sibsp', 'Parch'], axis = 1)  ## 동승한 가족의 수를 합하고, 기존 자료는 제거해야 한다. 그렇지 않으면 다중공선성 문제가 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361b10e-98b0-428d-ba38-1b02cdd7f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.fit(train, presets = 'best_quality')  ##  presets에 설정된 옵션 소환. 자원을 전부 지원해줄 테니, 가장 좋은 퀄리티를 내놓아라. > 시간 오래걸림, 성능 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c11e2b-8210-49b9-8ddc-1f8a938ad430",
   "metadata": {},
   "source": [
    "### **3. Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf1349c-46b2-480d-a64e-eae48f8ae1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f30629-c73f-4e53-817c-715dde09b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cycle\n",
    "\n",
    "## step 1\n",
    "X = pd.get_dummies(df_train.drop([반응변수 열], axis = 1))  ## 범주형 자료가 있을 때 반드시 사용\n",
    "y = df_train[반응변수열]\n",
    "XX = pd.get_dimmies(df_train)\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "predictr.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253dab27-ec60-4aa9-b0cf-b2d69500b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.coef_  ## coefficient, 계수를 내준다.\n",
    "predictr.intercept_  ## 절편을 내준다. 둘다 array로 반환하므로 사용 시 변환이 필요\n",
    "predictr.score(X, y)  ## R^2_score 값을 산출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9cc0b-33cc-486d-ac14-ea2019dbaa24",
   "metadata": {},
   "source": [
    "### **4. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8509f291-26bf-4c12-938f-bae2318f6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6275e-ba9b-4b2f-96e8-1d43fa74f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cycle\n",
    "\n",
    "## step 1\n",
    "X = pd.get_dummies(df_train.drop([반응변수 열], axis = 1))\n",
    "y = df_train[반응변수 열]\n",
    "XX = pd.get_dummies(df_test)\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "predictr.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ad1ad-f4fc-4fb5-89a5-931a68a2e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.score(X, y)  ## 예측한 반응변수가 원 반응변수 열 대비 얼마나 맞는 지 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a772412-1ce1-45ee-9ed7-35f6d872a1d4",
   "metadata": {},
   "source": [
    "### **5. 결측치 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1472de-f878-4280-a169-a342e8722235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import sklearn.impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9004e-106f-413b-ad9b-d4987a38ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info  ## 해당 결과 시 결측치가 많아보인다면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f8b08-644e-4b82-a3ba-13819cdc0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)  ## 특정 행에 결측치가 얼마나 있는지 시각화한다.\n",
    "msno.heatmap(df)  ## 결측치가 있는 구조(특정 행 부분에 밀집된 정도)가 비슷한 것 끼리 상관계수 내듯이\n",
    "msno.dendrogram(df)  ## 결측치 존재 구조가 비슷한 행끼리 엮어놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb9b93-241b-406a-8792-034e15f9b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr = sklearn.impute.SimpleImputer(strategy = '통계량 타입', fill_value = '채울 값')\n",
    "## strategy = 'mean', 'most_frequent', 'median',  'constant' > fill_value = 'value'\n",
    "imputr.fit(df)\n",
    "imputr.transform(df)  ## imputr.fit_transform(df) > 피팅과 전환을 한번에!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977da07-762c-462e-9758-0ac97fdbbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(imputr.fit_transform(df).reshape(-1))\n",
    "## impute 후 pd.Series로 전환할 때 꼭 1차원 배열로 바꿀 것! Series는 2차원 이상의 배열을 받을 수 없다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab213d5e-3c9e-4fc7-afdd-7bd628191f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr_int = sklearn.impute.SimpleImputer(strategy = 'mean')\n",
    "imputr_obj = sklearn.impute.SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "imputr_int.fit_transform(df.select_dtypes(include = 'number'))\n",
    "imputr_int.fit_transform(df.select_dtypes(exclude = 'number'))\n",
    "\n",
    "## df.select_dtypes()를 통해 형식에 따라 데이터프레임을 손쉽게 나누고, 각자 impute할 대상을 지정해줄 수 있다.\n",
    "## 일반적으로 범주형은 최빈값, 연속형은 평균으로 impute한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d1425-4202-4b38-9096-caea451f10e5",
   "metadata": {},
   "source": [
    "### **6. 로지스틱에서의 결측치 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5627bdf8-58b6-47c9-805b-65b6a8dbdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.impute\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46c0f9-7b29-4af9-8aec-0cebbc6f8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df):\n",
    "    \"\"\"\n",
    "    It impute missing, output imputed DataFrame.\n",
    "    \n",
    "    df : DataFrame include NaN value\n",
    "    \"\"\"\n",
    "    df_ = df.copy()  ## 데이터를 복사, 기존 데이터를 바꾸게 될 수도 있으므로 매우 유용하다.\n",
    "    \n",
    "    df_num = df_.select_dtypes(include = 'number')  ## 해당하는 데이터 타입만 선택\n",
    "    df_obj = df_.select_dtypes(exclude = 'number')\n",
    "    \n",
    "    df_[df_num.columns] = sklearn.impute.SimpleImputer(strategy = 'mean').fit_transform(df_num)\n",
    "    df_[df_obj.columns] = sklearn.impute.SimpleImputer(strategy = 'most_frequent').fit_transform(df_obj)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "## imputing하는 함수를 만든다. train, test셋을 다루려면 최소한 두 번은 imputing을 해야 하니... 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fce7a0-c17a-457c-8723-98feab6da594",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(impute_missing(df_train))  ## 범주형 열에 사용 시 주의해야 한다. 고유값을 가지는 열(이름, 티켓번호 등...)의 경우 더미를 행의 수만큼 만들수도 있음...\n",
    "## 꼭 필요없는 열은 드롭하고 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b759c-7c3e-4d80-9275-24e203804008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "X = pd.get_dummies(impute_missing(df_train.drop([고유값을 가지는 열들, 반응변수 열], axis = 1)))\n",
    "y = df_train['반응변수 열']\n",
    "XX = pd.get_dummies(impute_missing(df_test.drop([고유값을 가지는 열들], axis = 1)))\n",
    "\n",
    "## step 2\n",
    "## 기본 로지스틱 회귀분석 방법과 동일..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6bd10-fca7-42f5-a349-cbb3b583ee62",
   "metadata": {},
   "source": [
    "### **7. predictor의 이해**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ac9f2b-ddcc-4fbb-95fd-48c8a589ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53ac10-3300-4a92-819b-ff715f9057ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 로지스틱 회귀분석의 원리\n",
    "## 해당 개체에 처리가 취해질 확률이 0.5보다 크면 1, 0.5보다 작으면 0\n",
    "\n",
    "## 1\n",
    "X = df.drop(['employment'], axis = 1)\n",
    "y = df.employment\n",
    "\n",
    "## 2\n",
    "predictr = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "## 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## 4\n",
    "predictr.predict(X)  ## yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d7228-a87e-4244-b4b6-56990d84e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상기 과정에서 각 개체의 확률을 알고 싶으면...\n",
    "predictr.predict_proba(X)  ## n by 2의 행렬을 산출한다. 첫 행은 0일 확률, 둘째 행은 1일 확률이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c586a-3f27-4699-b7ff-aeb0d743f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = {'DataFrame(2d)': df_train_X, \n",
    "      'Seires(1d)': df_train_X.X,\n",
    "      'ndarray(2d)': np.array(df_train_X),\n",
    "      'ndarray(1d)': np.array(df_train_X).reshape(-1),\n",
    "      'list(2d)': np.array(df_train_X).tolist(),\n",
    "      'list(1d)': np.array(df_train_X).reshape(-1).tolist()}\n",
    "\n",
    "ys = {'DataFrame(2d)': df_train_y, \n",
    "      'Seires(1d)': df_train_y.y,\n",
    "      'ndarray(2d)': np.array(df_train_y),\n",
    "      'ndarray(1d)': np.array(df_train_y).reshape(-1),\n",
    "      'list(2d)': np.array(df_train_y).tolist(),\n",
    "      'list(1d)': np.array(df_train_y).reshape(-1).tolist()}\n",
    "\n",
    "def test(X,y):\n",
    "    try: \n",
    "        predictr = sklearn.linear_model.LinearRegression()\n",
    "        predictr.fit(X,y)\n",
    "        return 'no error'\n",
    "    except:\n",
    "        return 'error'  ## 예외사항(error) 발생 시의 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5989a3-3369-4ae7-8c8d-6fa61a10d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X, y에 들어갈 수 있는 형식\n",
    "\n",
    "{('X='+i,'y='+j): test(Xs[i],ys[j]) for i,j in itertools.product(Xs.keys(),ys.keys())}\n",
    "\n",
    "## itertools.product() : 원소들의 데카르트 곱을 리스트로 반환.\n",
    "## itertools.product('ABCD', repeat = 2)의 경우 크기가 2인 앞의 string 조합을 모두 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddd699-b680-43e7-921c-1dd8045d2f0e",
   "metadata": {},
   "source": [
    "```\n",
    "{('X=DataFrame(2d)', 'y=DataFrame(2d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=Seires(1d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=ndarray(2d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=ndarray(1d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=list(2d)'): 'no error',\r\n",
    " ('X=DataFrame(2d)', 'y=list(1d)'): 'no error',\r\n",
    " ('X=Seires(1d)', 'y=DataFrame(2d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=Seires(1d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=ndarray(2d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=ndarray(1d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=list(2d)'): 'error',\r\n",
    " ('X=Seires(1d)', 'y=list(1d)'): 'error',\r\n",
    " ('X=ndarray(2d)', 'y=DataFrame(2d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=Seires(1d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=ndarray(2d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=ndarray(1d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=list(2d)'): 'no error',\r\n",
    " ('X=ndarray(2d)', 'y=list(1d)'): 'no error',\r\n",
    " ('X=ndarray(1d)', 'y=DataFrame(2d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=Seires(1d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=ndarray(2d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=ndarray(1d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=list(2d)'): 'error',\r\n",
    " ('X=ndarray(1d)', 'y=list(1d)'): 'error',\r\n",
    " ('X=list(2d)', 'y=DataFrame(2d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=Seires(1d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=ndarray(2d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=ndarray(1d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=list(2d)'): 'no error',\r\n",
    " ('X=list(2d)', 'y=list(1d)'): 'no error',\r\n",
    " ('X=list(1d)', 'y=DataFrame(2d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=Seires(1d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=ndarray(2d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=ndarray(1d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=list(2d)'): 'error',\r\n",
    " ('X=list(1d)', 'y=list(1d)'): 'error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea526b9-4346-42f4-b007-e8fd2941a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## X에는 2차원 데이터만, y에는 1차원 2차원 모두 올 수 있다. y는 1차원 데이터를 은근히 바라고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca2548-1cfa-4a80-8388-695420b91df5",
   "metadata": {},
   "source": [
    "### **8. 스케일링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71123b85-e487-4a42-9d38-86c164658fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccade47-ebb8-4298-9456-184776d25df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputr = sklearn.preprocessing.MinMaxScaler()\n",
    "imputr.fit_transform(X)\n",
    "imputr.transform(XX)\n",
    "## sklearn.preprocessing.minmax_scale(X)  ## 잘 쓰진 않는다. XX에 똑같은 변환을 못해줌\n",
    "\n",
    "imputr = sklearn.preprocessing.StandardScaler()\n",
    "imputr.fit_transform(X)\n",
    "imputr.transform(XX)\n",
    "\n",
    "## X에서 fitting했으면 XX에는 fitting하지 않고 그대로 변환해주는 게 합리적이다.\n",
    "## X와 XX를 합쳐서 fitting하면 실격이다. 정보누수임(실제로는 그럴 일이 없으니까)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22bfa4-c25d-42c3-8c6c-07d33c1b66a1",
   "metadata": {},
   "source": [
    "1. **MinMaxSclaer**:\n",
    "    * 장점 : 원하는 범위 내로 데이터를 조정할 때 유용, 특히 신경망에서는 활성화 함수의 범위와 일치하도록 입력값을 조정하는 데 유용.\n",
    "    * 단점 : 이상치에 매우 민감하다.\n",
    "\n",
    "1. **StandardScaler**:\n",
    "   * 장점 : **이상치에 덜 민감**함, 많은 통계적 기법들 - **선형 알고리즘에서 잘 작동**함\n",
    "   * 단점 : 표준화된 데이터의 값이 특정 범위 내에 있음을 보장하지 않음.\n",
    "  \n",
    "> 단순히 MinMaxScaler는 데이터가 0\\~1 또는 -1~1사이의 범위에 있다고 가정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af1602-bcbe-452c-ab58-2e9616a5f7ac",
   "metadata": {},
   "source": [
    "### **9. 오버피팅, 다중공선성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748d95b3-95b3-4042-aac4-1f30600595d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677de24-f505-4c7a-a4cf-c51b46c6725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'str{}ing'.format(중괄호 안에 입력할 값)  ## 스트링 안에 중괄호가 있다면 언제든지 가능\n",
    "f'str{입력값:.4f}ing'  ## f스트링, 괄호 안에 특정 입력값을 넣어줄 수 있다.\n",
    "r'string'  ## markdown 문법으로 수식 작성 가능, ex) $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17125fd-a3b1-4290-93d7-c51bc0c1133f",
   "metadata": {},
   "source": [
    "> 반응변수와 관련성이 낮은 설명변수는(없는 설명변수) 오버피팅을 유발한다. 즉, 오차항을 적합하게 만든다.\n",
    ">\n",
    "> 설명변수끼리의 상관성이 높은 경우, 해당 설명변수들이 반응변수와의 상관성이 높더라도 오버피팅을 유발하고 이것을 다중공선성이라고 한다.\n",
    ">\n",
    "> 계수들의 합은 실제 계수와 동일하게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f29758-e766-4ef3-ab17-9315426656a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.model_selection.train_test_split(df, test_size = 0.3, random_state = value)\n",
    "## df_train, df_test를 순서대로 산출한다. 랜덤으로 샘플을 추출하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efb5d8-a0fb-4b80-a5ae-5796145b88c8",
   "metadata": {},
   "source": [
    "### **10. Lasso, Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1198c-639b-4fab-ad58-aa67945b0a42",
   "metadata": {},
   "source": [
    "`Lasso` : L1 penalty, `LogisticRegressionCV`의 옵션 `penalty = 'l1' solver = 'liblinear'`로 사용가능\n",
    "\n",
    ": 다수의 coef 값들을 0으로 만드는 수학적 장치\n",
    "\n",
    "> 패널티 : 상관성이 짙은 설명변수들의 계수값의 절대값을 구한 뒤에 합치고(L1-norm을 구하고), 그 값이 0에서 떨어져 있을수록 패널티 부여.\n",
    ">\n",
    "> **불필요한 설명변수는 오버피팅을 유발하니 몇 개만 남기고 배제함**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`Ridge` : L2 penalty,  `LogisticRegressionCV`의 옵션 `penalty = 'l2'`로 사용가능\n",
    "\n",
    ": coef의 값들을 가중치에 따라 분할하는 수학적 장치.\n",
    "\n",
    "> 패널티 : 상관성이 짙은 설명변수들의 계수값을 제곱한 뒤 합치고(L2-norm을 구하고), 그 값이 0에서 떨어져 있을수록 패널티 부여.\n",
    ">\n",
    "> **불필요한 설명변수는 오버피팅을 유발하니 불필요한 녀석이 없도록 만듦**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270d2f5-4599-412b-a5ee-55c469a7429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.linear_model.Lasso(alpha = float)\n",
    "sklearn.linear_model.LassoCV(alphas = list of floats)\n",
    "## alpha의 스케일이 작음. 0~2 정도\n",
    "\n",
    "sklearn.linear_model.Ridge(alpha = float)\n",
    "sklearn.linear_model.RidgeCV(alphas = list of floats)\n",
    "## alpha의 스케일이 큼. 5e2 ~ 5e10 정도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c077f-6216-498f-8ee8-7c40ee43fd3e",
   "metadata": {},
   "source": [
    "### **11. 선형모형의 적**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3080da0-bd0b-41bc-a627-2d2916feadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.impute\n",
    "import sklearn.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216af48d-405f-4af6-8150-3c52ebb4c5fa",
   "metadata": {},
   "source": [
    "* 결측치의 존재(뭐가 되었든 결측치는 모델이 감지하지 못하니까 직접 처리해줘야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb4bb4-8e25-4b2c-a950-001e32cf56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치를 제거\n",
    "df.info()\n",
    "df.loc[:, df.isna().mean() < 0.5]  ## 결측치가 50% 미만인 열만 선택\n",
    "df.dropna()  ## 결측치가 하나라도 있는 행을 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bfcfbb-21ad-4512-9e1b-e8669dcd99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치를 impute\n",
    "imputr = sklearn.impute.SimpleImputer(strategy = '')\n",
    "imputr.fit_transform(X)\n",
    "imputr.trainsform(XX)  ## 필요한 경우라면 fit_transform. 합쳐서 하면 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fb44e-f3a4-4279-bb68-5243267fbd5f",
   "metadata": {},
   "source": [
    "* 다중공선성의 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e473466-baa3-4fb8-b2df-ee6af6e6e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수 제거\n",
    "X.corr()  ## 설명변수 간 상관계수가 높을 시 직접 제거\n",
    "sns.heatmap(X.corr(), annot = True)\n",
    "\n",
    "## 패널티 계열 사용\n",
    "sklearn.linear_model.Lasso()\n",
    "sklearn.linear_model.Ridge()\n",
    "sklearn.linear_model.LogisticRegressionCV(penalty = , solver = )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df6903-c182-4c29-a7fb-c13cf32d320f",
   "metadata": {},
   "source": [
    "* 반응변수와 관련이 없는 설명변수 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3fb40-fe7a-4541-9914-35fe821a43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 변수 제거\n",
    "df.corr()\n",
    "sns.heatmap(df.corr(), annot = True)  ## 반응변수와의 상관계수가 낮을 시 직접 제거\n",
    "\n",
    "## 패널티 계열 사용\n",
    "sklearn.linear_model.Lasso()  ## LassoCV(alphas = np.linspace(a, b, n))\n",
    "sklearn.linear_model.LogisticRegressionCV(penalty = 'l1', solver = 'liblinear')\n",
    "## > 필요없는 설명변수는 계수를 0으로 만들어 무력화시킨다.\n",
    "\n",
    "## 더 많은 데이터를 확보...는 설명변수가 하나 늘어날수록 필요한 데이터의 수가 지수적으로 증가해서 어려움..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a0e42-fa75-4490-9499-a2d880bdd838",
   "metadata": {},
   "source": [
    "* 이상치의 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2e605-abdb-41eb-af71-483ed56281e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이상치를 제거하고 분석\n",
    "\n",
    "## 로버스트 선형회귀 계열을 이용\n",
    "\n",
    "## 이상치를 완화시키는 변환을 사용\n",
    "sklearn.preprocessing.PowerTransformer()  ## 조금 더 강제로 정규분포로 전환\n",
    "sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbccc21-d66c-48b9-9880-24815228ec35",
   "metadata": {},
   "source": [
    "* 교호작용의 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71781b3-ec68-4243-90a9-2cbcb02c325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 교호작용이 있는 열끼리 곱함\n",
    "df.assign(interaction = df.X1 * pd.get_dummies(df.X2, drop_first = True))\n",
    "\n",
    "## 교호작용에 영향을 받지 않는 모델 사용\n",
    "sklearn.tree.DecisionTreeRegressor()  ## Linear\n",
    "sklearn.tree.DecisionTreeClassifier()  ## Logistic\n",
    "\n",
    "## 교호작용 판단\n",
    "ggplot(df) + geom_point(aes(x = '설명변수 1', y = '반응변수', color = '설명변수 2'))  ## 연속형인 경우\n",
    "## > 해당 결과에서 색상 별 언더라잉을 그릴 수 있으면, 교호작용이 있다고 판단할 수 있다.\n",
    "df_train.pivot_table(index = '설명변수 1', columns = '설명변수 2', values = '반응변수', aggfunc = 'mean')  ## 범주형\n",
    "## > 해당 결과에서 둘 모두가 바뀌었을 때 평균 차이가 더 크다면, 교호작용이 있을 것으로 예상할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca791bb-3ec0-4c2f-af4d-4c5676b198e2",
   "metadata": {},
   "source": [
    "### **12. 의사결정나무 활용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd3aeca-e4d9-4ef7-8c3d-3b8408c808d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd77e4-cecb-46ae-ac7b-b09d5b906825",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다중공선성, 반응변수와 관련이 없는 설명변수, 이상치, 교호작용\n",
    "## 설명변수의 수가 많아질수록 tree계열의 정확도가 Lasso나 Ridge보다 좋아짐.\n",
    "## 적합에 관여한 구간 외의 값이 인풋되면, tree 모형은 그 값을 잘 예측하지 못한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a706c-0f0c-495a-b421-657a47797e19",
   "metadata": {},
   "source": [
    "### **13. 기타 팁**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abee73f-1b64-49e7-977b-69eef40f2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 열에 유니크한 값들이 얼마나 있는지 파악하는 코드\n",
    "{col : len(set(df_train[col])) for col in df_train.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c408e21-8c9c-4de6-864a-7d25ad0e0cc5",
   "metadata": {},
   "source": [
    "## Final Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df1be4-7e40-4f38-8102-c03d9b7a53fd",
   "metadata": {},
   "source": [
    "### **14. 플랏 애니메이션**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c5b74-7df0-4ca4-bfa5-583574862eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0154c6b-38d6-4bee-aa09-a715625df053",
   "metadata": {},
   "source": [
    "* `fig`, `function`, `frame` 이 세 가지 변수가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfa319-bea6-41e9-8a48-69ea30df7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1 : create figure\n",
    "fig = plt.figure()\n",
    "\n",
    "## step 2 : define function\n",
    "def func(frame) :\n",
    "    ax = fig.gca()  ## axis를 가져옴\n",
    "    ax.clear()  ## 다음 프레임으로 넘어갈 때 기존 axis를 비워줌\n",
    "    ax.plot()  ## 플로팅(프레임에 따라 변하도록)\n",
    "    ax.set_title()  ## 타이틀 설정 및 레이블링\n",
    "\n",
    "## step 3 : create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig, func, frames = int\n",
    ")\n",
    "\n",
    "## step 4 : output\n",
    "display(IPython.display.HTML(ani.to_jshtml()))  ## 자바스크립트 html로 들여온 것을 IPython으로 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c22529-1369-4058-99be-769e149b6630",
   "metadata": {},
   "source": [
    "### **15. 의사결정나무 작동원리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a224e-aee2-44c0-9b0b-007035db8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import IPython\n",
    "import sklearn.tree\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f15c4-7d8a-4bc4-8908-354a04e336ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.tree.DecisionTreeRegressor(\n",
    "    max_depth = int, ## 1 이상의 정수\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23017681-632d-48a5-aeb7-844202225efb",
   "metadata": {},
   "source": [
    "* `max_depth`에 따른 적합 그래프 애니메이션 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29ef43-f468-473f-8e06-ca089da5ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = [sklearn.tree.DecisionTreeRegressor(max_depth = i+1) for i in range(frame)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced825c-d958-4d46-b886-271815eaf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create figure\n",
    "fig = plt.figure()\n",
    "\n",
    "## create predictr and fitting : 리소스 절감, 명확하게 하려면 func에 삽입할 것\n",
    "predictrs = [sklearn.tree.DecisionTreeRegressor(max_depth = i+1) for i in range(10)]  ## i는 0부터 시작이므로 1을 더해준다.\n",
    "\n",
    "for predictr in predictrs :\n",
    "    predictr.fit(X, y)\n",
    "\n",
    "## define function\n",
    "def func(frame):\n",
    "    ax = fig.gca()\n",
    "    ax.clear()\n",
    "    ax.plot(X, y, 'o', alpha = 0.5, label = 'True')\n",
    "    ax.plot(X, predictr[frame].predict(X), '--', label = 'Predicted')\n",
    "    ax.set_title('max_depth = {}'.format(str(frame+1)))  ## f-string을 사용하면 f'max_depth = {str(frame+1)}'\n",
    "\n",
    "## create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = 10  ## max_depth = 10 까지 시각화\n",
    ")\n",
    "\n",
    "## display\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4cfac3-6b34-4b2e-8a44-cb4206af02f7",
   "metadata": {},
   "source": [
    "* 노드 분할 결정기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1e2e7-b14c-4d2b-8fec-af0f5f3b0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(y, y_hat)  ## predictr.score()와 동일('Regression Model'에서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9a6e8-7e48-4017-b9ae-a80fa5ac9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X, y, c) :\n",
    "    \"\"\"\n",
    "    X와 y, 분할할 구간을 넣어주면 max_depth = 1일 때의 구간에 따른 예측값을 반환하는 함수.\n",
    "    \"\"\"\n",
    "    X = np.array(X).reshape(-1)  ## 1차원으로 깨줌\n",
    "    y = np.array(y)\n",
    "    yhat = y*0  ## 초기값 배정\n",
    "    yhat[X<=c] = y[X<=c].mean()  ## bool list로 슬라이싱\n",
    "    yhat[X>c] = y[X>c].mean()\n",
    "    \n",
    "    return yhat  ## 분할 값이 c일 때의 예측치\n",
    "\n",
    "cuts = np.arange(-5, 15)\n",
    "\n",
    "## create figure\n",
    "fig = plt.figure()\n",
    "\n",
    "## define function\n",
    "def func(frame) :\n",
    "    ax = fig.gca()\n",
    "    ax.clear()\n",
    "    yhat = fit_predict(X, y, cuts[frame])  ## frame번째에 해당하는 분할 값이 들어감\n",
    "    \n",
    "    ax.plot(X, y, 'o', alpha = 0.5, label = 'True')\n",
    "    ax.plot(X, yhat, '--', label = 'Predicted')\n",
    "    ax.set_title(f'c = {cuts[frame]},  R-squared = {round(sklearn.metrics.r2_score(y, yhat), 4)}')  ## 들어가야 할 함수가 많으므로 f-string을 이용했음\n",
    "    ax.legend()\n",
    "\n",
    "## create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = len(cuts)  ## yhat값을 전부 담기 위해서\n",
    ")\n",
    "\n",
    "## display\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04446c86-f0f2-44e8-a65e-1cace758fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최댓값을 찾는 방법\n",
    "cuts = np.arange(-5, 15, 0.001).round(5)\n",
    "scores = np.array([sklearn.metrics.r2_score(y, fit_predict(X, y, c)) for c in cuts])\n",
    "display(pd.DataFrame({'cut':cuts, 'score':scores}).plot.line(x = 'cut', y = 'score', backend = 'plotly'))\n",
    "display(cuts[scores.argmax()])  ## 최댓값인 argument, x의 해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641ce60-d9f9-4850-ace9-06c543c8da62",
   "metadata": {},
   "source": [
    "* `plot_tree` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abffaa1-846b-4ef9-b0ea-1116293c6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import graphviz\n",
    "\n",
    "#-#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12f9d4-2918-4957-874b-2aed1da6d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot_tree를 개별 axe에 삽입\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots(2,1)\n",
    "ax[0].plot(y, y, '--')\n",
    "ax[0].plot(y, predictr.predict(X), 'o', alpha = 0.1)\n",
    "\n",
    "sklearn.tree.plot_tree(\n",
    "    predictr,\n",
    "    max_depth = int,  ## predictr에서의 깊이 이하여야 함\n",
    "    feature_names = X.columns.to_list(),  ## 노드들에 대한 이름을 지정해줌, 순서대로 넣어야 함.\n",
    "    ax = ax[1]  ## 해당 옵션으로 i번째 ax에 삽입이 가능하다.\n",
    ");\n",
    "\n",
    "## dpi를 조절해서 전부 보이게 만드는 방법, 사진이 왕창 커짐\n",
    "fig.suptitle('str')\n",
    "fig.set_dpi(int)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ac4a4-1bc7-4259-bfc4-b91b59ed5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sklearn.tree.export_graphviz(\n",
    "    predictr,\n",
    "    feature_names = X.columns.to_list()\n",
    ")\n",
    "\n",
    "graphviz.Source(g)  ## plot_tree 개체 자체를 조정하는 방법\n",
    "graphviz.Source(g).render('tree', format = 'pdf')  ## 파일로 저장도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984d50b-119c-4667-ac8e-1c4dbf414c78",
   "metadata": {},
   "source": [
    "* 추가 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4dfb2-c08e-4af3-a912-948456636568",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.tree.DecisionTreeRegressor(max_features = int or rate, random_state = int)\n",
    "## 적합 시 최대 몇 개의 설명변수를 사용할 것인지 1 이상의 정수나 비율로 지정한다. fit()할 때마다 결과값이 달라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff12ff8-f1b5-42f2-acca-c7ea67282b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr = sklearn.tree.DecisionTreeRegressor()\n",
    "predictr.fit(sample_weight = 'int list')  ## 몇 번째 값을 얼마나 중요하게 여길 지 그 비중을 입력해준다. 배깅의 핵심 코드이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfd2f5-a83b-46a9-b804-4c2834cdf2c6",
   "metadata": {},
   "source": [
    "### **16. 배깅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b55806-bc91-4443-beda-570ad59620a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "import matplotlib.animation\n",
    "import IPython\n",
    "\n",
    "#-#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaffb3f-a6ca-49d0-8380-70a58de258d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "X = '더미화 한 설명변수열'\n",
    "y = '반응변수열'\n",
    "\n",
    "## step 2\n",
    "predictr = sklearn.ensemble.BaggingRegressor()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d093b-1ecf-476f-91d8-3ce4a1318dee",
   "metadata": {},
   "source": [
    "> 기본적으로 부트스트랩한 10개의 샘플을 이용해서 퓨어 트리로 적합한 뒤 그 값들의 평균을 내는 알고리즘이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39215b6a-0432-4e6d-b53f-b2355ca2b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictr.estimators_  ## 적합한 개별 트리 모듈, predictr.estimators_[i].predict(X)를 하면 그 예측값이 다 다르게 나온다.\n",
    "predictr.estimators_samples_  ## 재표본 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d67cf-f4e9-49ff-aaed-85c959a51bf8",
   "metadata": {},
   "source": [
    "* 내부 모형과 수제 모형 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d232b-bee4-4b36-a176-aaa15807caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create figure\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "## define function\n",
    "def func(frame) :\n",
    "    ax[0].clear()  ## 배깅으로 적합한 predictr\n",
    "    sklearn.tree.plot_tree(\n",
    "        predictr.estimators_[frame],\n",
    "        feature_names = X.columns.to_list(),\n",
    "        max_depth = 1,\n",
    "        ax = ax[0]\n",
    "    )\n",
    "    ax[0].set_title('Bagging Predictor')\n",
    "\n",
    "    ax[1].clear()  ## 기본 의사결정나무로 적합한 predictr\n",
    "    tree = sklearn.tree.DecisionTreeRegressor()\n",
    "    tree.fit(X_arr[predictr.estimators_samples_[frame]], y_arr[predictr.estimators_samples_[frame]])\n",
    "    # tree.fit(X, y, sample_weight = [sum(predictr.estimators_samples_[frame] == i) for i in range(len(predictr.estimators_samples_[0]))])  ## 이게 더 정확하긴 함\n",
    "    sklearn.tree.plot_tree(\n",
    "        tree,\n",
    "        feature_names = X.columns.to_list(),\n",
    "        max_depth = 1,\n",
    "        ax = ax[1]\n",
    "    )\n",
    "    ax[1].set_title('Pure Tree')\n",
    "\n",
    "## create animation figure\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = 10\n",
    ")\n",
    "\n",
    "## display\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b655a2-5db8-47c3-9578-5355958cfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([tree.predict(X) for tree in predictr.estimators_]).mean(axis = 0)  ## 해당 값은 predictr.predict(X)와 동일하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90daccdb-6348-4ebb-8b74-25e66fea4d7d",
   "metadata": {},
   "source": [
    "* `ensemble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01216151-e776-41ab-a4a4-a115a1506e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(trees, i=None) :\n",
    "    \"\"\"\n",
    "    tree들이 엮여있는 predictr를 입력하면, i번째 트리까지의 평균을 yhat으로 반환하는 함수\n",
    "    \"\"\"\n",
    "    if i is None :\n",
    "        i = len(trees.estimators_)  ## i가 trees의 length를 초과해도 로직 상 문제가 없다.\n",
    "    yhat = np.array([tree.predict(X) for tree in trees.estimators_[:i+1]]).mean(axis = 0)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a80d2-7927-4553-b18d-0f37aba655db",
   "metadata": {},
   "source": [
    "* 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17775510-db04-45d7-84c6-b409cb0eeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize = (13, 3))\n",
    "\n",
    "def func(i) :\n",
    "    for a in ax:\n",
    "        a.clear()\n",
    "\n",
    "    ## step 0 -- data import\n",
    "    ax[0].set_title('Step 0')\n",
    "    ax[0].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "\n",
    "    ## step 1 -- Resampling\n",
    "    ax[1].set_title('Step 1 : ReSampling')\n",
    "    ax[1].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "    ax[1].plot(X_arr[samples[i]], y_arr[samples[i]], 'o', alpha = 0.3)\n",
    "    \n",
    "    ## step 2 -- fitting\n",
    "    ax[2].set_title('Step 3 : Fitting')\n",
    "    ax[2].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "    ax[2].plot(X_arr[samples[i]], y_arr[samples[i]], 'o', alpha = 0.3)\n",
    "    ax[2].plot(X, trees[i].predict(X), '--')  ## 개별 tree의 적합\n",
    "    \n",
    "    ## step 3 -- ensemble\n",
    "    ax[3].set_title('Step 4 : Ensemble')\n",
    "    ax[3].plot(X, y, 'o', color = 'grey', alpha = 0.2)\n",
    "    ax[3].plot(X, ensemble(predictr, i), '--', color = 'C1')\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    func,\n",
    "    frames = len(predictr.estimators_features_)\n",
    ")\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46ccb6-a4cd-44db-a21c-06579a50c900",
   "metadata": {},
   "source": [
    "### **17. 랜덤포레스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7b310-e5ba-4280-a9a4-58a54c0f7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e702c7d-8ad6-40b0-8047-97839f3b19cc",
   "metadata": {},
   "source": [
    "* `배깅 + max_features` : 트리들의 다양성 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4af496-3a5a-4719-b187-7de29fbeec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "## step 2\n",
    "predictr = sklearn.ensemble.RandomForestRegressor(\n",
    "    max_depth = 1,\n",
    "    max_features = 1/3  ## parameter를 float으로 지정해줄 경우 비율로 지정됨, 디폴트가 1.0이므로 반드시 지정해줄 것\n",
    ")\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee5006-8e3e-4aeb-9c81-ce645f235c86",
   "metadata": {},
   "source": [
    "* 랜덤포레스트 재현(`predictr.estimators_samples_`같은 거 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec2588-32f2-42f9-9925-a8f4f86a2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## max_features와 random_state가 중점\n",
    "predictr.estimators_  ## 100개의 트리\n",
    "rs = [tree.random_state for tree in predictr.estimators_]  ## 100개의 random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace42b13-6d58-4f8c-ac64-1df861c50a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_forest = [sklearn.tree.DecisionTreeRegressor(max_depth = 1, max_features = 1/3, random_state = r) for r in rs]  ## 100개의 다른 random_state를 갖는 트리 생성(숲)\n",
    "\n",
    "sample = sklearn.ensemble._forest._generate_sample_indices\n",
    "my_index = [sample(random_state = r, n_samples = 1338, n_samples_bootstrap = 1338) for r in rs]  ## 부트스트랩으로 random_state가 일치하는 샘플들의 인덱스를 뽑는다.\n",
    "\n",
    "for idx, tree in zip(my_index, my_forest) :\n",
    "    X_sample, y_sample = X.loc[idx], y.loc[idx]\n",
    "    ## or np.array(X)[idx], np.array(y)[idx]\n",
    "    tree.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70429ed1-a1a3-478b-98c5-80e7669bb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 엄밀한 코드\n",
    "for idx, tree in zip(my_index, my_forest) :\n",
    "    weight = [sum(my_index == i) for i in range(len(my_index))]\n",
    "    tree.fit(X, y, sample_weight = weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75a302-828d-4ba0-8362-1c27017106ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(forest) :\n",
    "    \"\"\"\n",
    "    적합된 트리들을 넣으면 평균을 반환하는 함수\n",
    "    \"\"\"\n",
    "    return np.stack([tree.predict(X) for tree in forest]).mean(axis = 0)\n",
    "\n",
    "ensemble(my_forest) ## predictr.predict(X)와 그 값이 동일해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44223e7-e5d7-4f67-a74e-96f139ff78ba",
   "metadata": {},
   "source": [
    "### **18. 부스팅**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89114ccf-a4fb-4ede-84f0-94d6827c1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "#---#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#---#\n",
    "import matplotlib.animation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f647e62-1483-4231-816a-e4c1acd8d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1\n",
    "## step 2\n",
    "predictr = sklearn.ensemble.GradientBoostingRegressor()\n",
    "\n",
    "## step 3\n",
    "predictr.fit(X, y)\n",
    "\n",
    "## step 4\n",
    "yhat = predictr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b2339-391f-4371-9d06-47eb4d3dc359",
   "metadata": {},
   "source": [
    "* 로우 레벨부터 적합하고(`max_depth`를 낮게 가져감으로써) 잔차를 적합해나가는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae7772-4b4b-4ca7-8b66-08ece9f0966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [t[0] for t in predictr.estimators_]  ## 이중 리스트라 풀어줘야 트리 개체가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226fb0d-4ebc-4a46-8196-ccb8bd72947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 어셈블리 코드\n",
    "def ensemble(trees, i = None) :\n",
    "    if (i is None) or (i+1 > len(trees)) :\n",
    "        i = len(trees)\n",
    "    else :\n",
    "        i = i+1  ## loc하게 되면 그것 다음것까지로 넣어야되니까.\n",
    "    predictions = [trees[j].predict(X) for j in range(i)]\n",
    "    yhat = np.array(predictions[:i]).sum(axis = 0)*0.1 + y.mean()  ## 축의 값들을 가중치를 반영하여 더해야 함.\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cc934-aff3-495c-a221-324e88820ffe",
   "metadata": {},
   "source": [
    "* 적합되는 장면 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ee5a3-0435-4796-b2dc-3be4bb5e02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "plt.close()  ## 쌩 피규어가 콘솔에 안뜨도록 함. 이중으로 뜨는 거 방지, 쓸모없는 거 안나오도록 함\n",
    "\n",
    "def func(frame) :\n",
    "    ax.clear()\n",
    "    ax.plot(X, y, 'o', label = 'RawData')  ## 원자료\n",
    "    ax.plot(X, ensemble(trees, frame), '--', label = 'WeakPredictor (ver ({})'.format(round((frame+1)*0.01, 3)))\n",
    "    ax.legend()\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, func, frames = 100)\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6a517-7f75-4f73-8d4b-6d5d67ac8f76",
   "metadata": {},
   "source": [
    "* 손으로 재현하여 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ede67f-be98-4b9e-9a87-a3b7caf542ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trees = []\n",
    "my_residuals = []\n",
    "\n",
    "res = y - y.mean()  ## 잔차(태초의)\n",
    "\n",
    "## 100번 공부\n",
    "for i in range(100) :\n",
    "    tree = sklearn.tree.DecisionTreeRegressor(max_depth = 3, criterion = 'friedman_mse')\n",
    "    tree.fit(X, res)  ## 아직 적합되지 못한 잔차에 대해서 적합을 함(오버피팅???)\n",
    "    yhat = tree.predict(X)\n",
    "    res = res - yhat*0.1  ## 학습한 것을 다 반영하지 말고 learning_rate만큼만 반영하자. (그래야 다양하게 적합할 수 있음)\n",
    "    my_trees.append(tree)\n",
    "    my_residuals.append(res)\n",
    "\n",
    "## 덜 깊게 적합하는 선에서 잔차를 적합하고, 또 적합하고... 이 과정을 100번 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c192c6-b4fa-44e3-8cd4-620b32f3a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "plt.close()\n",
    "\n",
    "def func(frame) :\n",
    "    for i in range(2) :\n",
    "        for j in range(2) :\n",
    "            ax[i,j].clear()\n",
    "            ax[i,j].plot(X, y, 'o', alpha = 0.5)\n",
    "\n",
    "    ax[0,0].plot(X, ensemble(trees, frame), '--')  ## Boosting Trees\n",
    "    ax[0,1].plot(X, ensemble(my_trees, frame), '--')  ## Pure Trees(직접 적합한 모형)\n",
    "\n",
    "    sklearn.tree.plot_tree(trees[frame], max_depth = 0, feature_names = X.columns.to_list(), ax = ax[1,0])  ## Boosing Trees\n",
    "    sklearn.tree.plot_tree(my_trees[frame], max_depth = 0, feature_names = X.columns.to_list(), ax = ax[1,1])  ## Pure Trees(직접 적합한 모형)\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, func, frames = 100)\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8b795-48af-4473-b3e0-edbe3946eec4",
   "metadata": {},
   "source": [
    "* 과정 별 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2028ed-c533-4dd3-bd5d-19534cb7131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize = (10, 3))\n",
    "plt.close()\n",
    "\n",
    "def func(frame) :\n",
    "    for a in ax :\n",
    "        a.clear()\n",
    "\n",
    "    ax[0].set_title('Step 0')\n",
    "    ax[0].plot(X, y, 'o', alpha = 0.5)\n",
    "    ax[0].plot(X, ensemble(my_trees, frame), '--')\n",
    "    \n",
    "    ax[1].set_title('Step 1 : Residuals')  ## 적합하고 남은 잔차를 계산\n",
    "    ax[1].plot(X, my_residuals[frame], 'o', alpha = 0.5)  ## 잔차 시각화\n",
    "    ax[1].set_ylim(-20,20)\n",
    "    \n",
    "    ax[2].set_title('Step 2 : Fitting')  ## 잔차에 대해 트리로 적합\n",
    "    ax[2].plot(X, my_residuals[frame], 'o', alpha = 0.5)\n",
    "    ax[2].plot(X, my_trees[frame].predict(X), '--')  ## 잔차에 대한 적합선\n",
    "    ax[2].set_ylim(-20,20)\n",
    "    \n",
    "    ax[3].set_title('Step 3 : Update')\n",
    "    ax[3].plot(X, y, 'o', alpha = 0.5)\n",
    "    ax[3].plot(X, ensemble(my_trees, frame), '--', color = 'C1')\n",
    "    ax[3].plot(X, ensemble(my_trees, frame+1), '--', color = 'C3')\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, func, frames = 100)\n",
    "\n",
    "display(IPython.display.HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c87c98-01bd-4271-8667-1fed197c3e2f",
   "metadata": {},
   "source": [
    "### **19. 평가지표의 이해**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675907c-98a6-4fd0-9ef6-f282eb5feea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
